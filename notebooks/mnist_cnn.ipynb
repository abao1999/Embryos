{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kP4isy2XF948"
   },
   "source": [
    "# Handwritten Digit Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6jsphg8rGME5"
   },
   "source": [
    "I copied this tutorial for CNN MNIST from https://mxnet.apache.org/versions/1.7.0/api/python/docs/tutorials/packages/gluon/image/mnist.html (the first step is to import the mxnet library which contains gluoncv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 182
    },
    "id": "kHl4iv4lEFha",
    "outputId": "a79030ec-b847-4188-ea2d-1ed3eb18dc67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mxnet in /usr/local/lib/python3.6/dist-packages (1.7.0.post1)\n",
      "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.6/dist-packages (from mxnet) (1.18.5)\n",
      "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet) (2.23.0)\n",
      "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from mxnet) (0.8.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "pip install mxnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KPjH7BqSGEZV"
   },
   "source": [
    "In this tutorial, we’ll give you a step by step walk-through of how to build a hand-written digit classifier using the MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RLkPrgniFKbL"
   },
   "source": [
    "MNIST is a widely used dataset for the hand-written digit classification task. It consists of 70,000 labeled 28x28 pixel grayscale images of hand-written digits. The dataset is split into 60,000 training images and 10,000 test images. There are 10 classes (one for each of the 10 digits). The task at hand is to train a model using the 60,000 training images and subsequently test its classification accuracy on the 10,000 test images.\n",
    "\n",
    "Before we define the model, let’s first fetch the MNIST dataset.\n",
    "\n",
    "The following source code downloads and loads the images and the corresponding labels into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "yYIP-3R6ELVS"
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "\n",
    "# Fixing the random seed\n",
    "mx.random.seed(42)\n",
    "\n",
    "mnist = mx.test_utils.get_mnist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gOiN-XR3FY1u"
   },
   "source": [
    "After running the above source code, the entire MNIST dataset should be fully loaded into memory. Note that for large datasets it is not feasible to pre-load the entire dataset first like we did here. What is needed is a mechanism by which we can quickly and efficiently stream data directly from the source. MXNet Data iterators come to the rescue here by providing exactly that. Data iterator is the mechanism by which we feed input data into an MXNet training algorithm and they are very simple to initialize and use and are optimized for speed. During training, we typically process training samples in small batches and over the entire training lifetime will end up processing each training example multiple times. In this tutorial, we’ll configure the data iterator to feed examples in batches of 100. Keep in mind that each example is a 28x28 grayscale image and the corresponding label.\n",
    "\n",
    "Image batches are commonly represented by a 4-D array with shape (batch_size, num_channels, width, height). For the MNIST dataset, since the images are grayscale, there is only one color channel. Also, the images are 28x28 pixels, and so each image has width and height equal to 28. Therefore, the shape of input is (batch_size, 1, 28, 28). Another important consideration is the order of input samples. When feeding training examples, it is critical that we don’t feed samples with the same label in succession. Doing so can slow down training. Data iterators take care of this by randomly shuffling the inputs. Note that we only need to shuffle the training data. The order does not matter for test data.\n",
    "\n",
    "The following source code initializes the data iterators for the MNIST dataset. Note that we initialize two iterators: one for train data and one for test data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "DIugYIUMEJMz"
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "train_data = mx.io.NDArrayIter(mnist['train_data'], mnist['train_label'], batch_size, shuffle=True)\n",
    "val_data = mx.io.NDArrayIter(mnist['test_data'], mnist['test_label'], batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YsI7W77NFc6v"
   },
   "source": [
    "We will cover a couple of approaches for performing the hand written digit recognition task. The first approach makes use of a traditional deep neural network architecture called Multilayer Perceptron (MLP). We’ll discuss its drawbacks and use that as a motivation to introduce a second more advanced approach called Convolution Neural Network (CNN) that has proven to work very well for image classification tasks.\n",
    "\n",
    "Now, let’s import required nn modules\n",
    "\n",
    "Note: only CNN architecture is present in this CS101 notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "WGIhhbgFEejO"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import mxnet as mx\n",
    "from mxnet import gluon\n",
    "from mxnet.gluon import nn\n",
    "from mxnet import autograd as ag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "trFp-69pFpX2"
   },
   "source": [
    "Earlier, we briefly touched on a drawback of MLP when we said we need to discard the input image’s original shape and flatten it as a vector before we can feed it as input to the MLP’s first fully connected layer. Turns out this is an important issue because we don’t take advantage of the fact that pixels in the image have natural spatial correlation along the horizontal and vertical axes. A convolutional neural network (CNN) aims to address this problem by using a more structured weight representation. Instead of flattening the image and doing a simple matrix-matrix multiplication, it employs one or more convolutional layers that each performs a 2-D convolution on the input image.\n",
    "\n",
    "A single convolution layer consists of one or more filters that each play the role of a feature detector. During training, a CNN learns appropriate representations (parameters) for these filters. Similar to MLP, the output from the convolutional layer is transformed by applying a non-linearity. Besides the convolutional layer, another key aspect of a CNN is the pooling layer. A pooling layer serves to make the CNN translation invariant: a digit remains the same even when it is shifted left/right/up/down by a few pixels. A pooling layer reduces a n x m patch into a single value to make the network less sensitive to the spatial location. Pooling layer is always included after each conv (+ activation) layer in the CNN.\n",
    "\n",
    "The following source code defines a convolutional neural network architecture called LeNet. LeNet is a popular network known to work well on digit classification tasks. We will use a slightly different version from the original LeNet implementation, replacing the sigmoid activations with tanh activations for the neurons.\n",
    "\n",
    "A typical way to write your network is creating a new class inherited from gluon.Block class. We can define the network by composing and inheriting Block class as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "DouYrQolEUEh"
   },
   "outputs": [],
   "source": [
    "import mxnet.ndarray as F\n",
    "\n",
    "class Net(gluon.Block):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Net, self).__init__(**kwargs)\n",
    "        with self.name_scope():\n",
    "            # layers created in name_scope will inherit name space\n",
    "            # from parent layer.\n",
    "            self.conv1 = nn.Conv2D(20, kernel_size=(5,5))\n",
    "            self.pool1 = nn.MaxPool2D(pool_size=(2,2), strides = (2,2))\n",
    "            self.conv2 = nn.Conv2D(50, kernel_size=(5,5))\n",
    "            self.pool2 = nn.MaxPool2D(pool_size=(2,2), strides = (2,2))\n",
    "            self.fc1 = nn.Dense(500)\n",
    "            self.fc2 = nn.Dense(10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.tanh(self.conv1(x)))\n",
    "        x = self.pool2(F.tanh(self.conv2(x)))\n",
    "        # 0 means copy over size from corresponding dimension.\n",
    "        # -1 means infer size from the rest of dimensions.\n",
    "        x = x.reshape((0, -1))\n",
    "        x = F.tanh(self.fc1(x))\n",
    "        x = F.tanh(self.fc2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "09vcnbpoFrSr"
   },
   "source": [
    "We just defined the forward function here, and the backward function to compute gradients is automatically defined for you using autograd. We also imported mxnet.ndarray package to use activation functions from ndarray API.\n",
    "\n",
    "Now, We will create the network as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "kOcqNkg6EaJm"
   },
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nrPmoPbgFuAK"
   },
   "source": [
    "Now we train LeNet with similar hyper-parameters as before. Note that, if a GPU is available, we recommend using it. This greatly speeds up computation given that LeNet is more complex and compute-intensive than the previous multilayer perceptron. To do so, we only need to change mx.cpu() to mx.gpu() and MXNet takes care of the rest. Just like before, we’ll stop training after 10 epochs.\n",
    "\n",
    "Training and prediction can be done in the similar way as we did for MLP.\n",
    "\n",
    "## Initialize parameters and optimizer\n",
    "We will initialize the network parameters as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "7LrWZqZiEjYO"
   },
   "outputs": [],
   "source": [
    "# set the context on GPU is available otherwise CPU\n",
    "ctx = [mx.gpu() if mx.test_utils.list_gpus() else mx.cpu()]\n",
    "net.initialize(mx.init.Xavier(magnitude=2.24), ctx=ctx)\n",
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': 0.03})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9nRY3ywpFzrw"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "id": "JnCAAv8gElmJ",
    "outputId": "fa3bba38-f09b-4ee1-b99d-ab8d77361a88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training acc at epoch 0: accuracy=0.868167\n",
      "training acc at epoch 1: accuracy=0.942667\n",
      "training acc at epoch 2: accuracy=0.957600\n",
      "training acc at epoch 3: accuracy=0.964900\n",
      "training acc at epoch 4: accuracy=0.969567\n",
      "training acc at epoch 5: accuracy=0.973017\n",
      "training acc at epoch 6: accuracy=0.975200\n",
      "training acc at epoch 7: accuracy=0.977433\n",
      "training acc at epoch 8: accuracy=0.979183\n",
      "training acc at epoch 9: accuracy=0.980033\n"
     ]
    }
   ],
   "source": [
    "epoch = 10\n",
    "\n",
    "# Use Accuracy as the evaluation metric.\n",
    "metric = mx.metric.Accuracy()\n",
    "softmax_cross_entropy_loss = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "\n",
    "for i in range(epoch):\n",
    "    # Reset the train data iterator.\n",
    "    train_data.reset()\n",
    "    # Loop over the train data iterator.\n",
    "    for batch in train_data:\n",
    "        # Splits train data into multiple slices along batch_axis\n",
    "        # and copy each slice into a context.\n",
    "        data = gluon.utils.split_and_load(batch.data[0], ctx_list=ctx, batch_axis=0)\n",
    "        # Splits train labels into multiple slices along batch_axis\n",
    "        # and copy each slice into a context.\n",
    "        label = gluon.utils.split_and_load(batch.label[0], ctx_list=ctx, batch_axis=0)\n",
    "        outputs = []\n",
    "        # Inside training scope\n",
    "        with ag.record():\n",
    "            for x, y in zip(data, label):\n",
    "                z = net(x)\n",
    "                # Computes softmax cross entropy loss.\n",
    "                loss = softmax_cross_entropy_loss(z, y)\n",
    "                # Backpropogate the error for one iteration.\n",
    "                loss.backward()\n",
    "                outputs.append(z)\n",
    "        # Updates internal evaluation\n",
    "        metric.update(label, outputs)\n",
    "        # Make one step of parameter update. Trainer needs to know the\n",
    "        # batch size of data to normalize the gradient by 1/batch_size.\n",
    "        trainer.step(batch.data[0].shape[0])\n",
    "    # Gets the evaluation result.\n",
    "    name, acc = metric.get()\n",
    "    # Reset evaluation result to initial state.\n",
    "    metric.reset()\n",
    "    print('training acc at epoch %d: %s=%f'%(i, name, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7MaZqtNXF2Ch"
   },
   "source": [
    "## Prediction\n",
    "Finally, we’ll use the trained LeNet model to generate predictions for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "rIW2NJZiEn85",
    "outputId": "c3c490e2-b57d-40c7-e8e6-7679425889e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: accuracy=0.982500\n"
     ]
    }
   ],
   "source": [
    "# Use Accuracy as the evaluation metric.\n",
    "metric = mx.metric.Accuracy()\n",
    "# Reset the validation data iterator.\n",
    "val_data.reset()\n",
    "# Loop over the validation data iterator.\n",
    "for batch in val_data:\n",
    "    # Splits validation data into multiple slices along batch_axis\n",
    "    # and copy each slice into a context.\n",
    "    data = gluon.utils.split_and_load(batch.data[0], ctx_list=ctx, batch_axis=0)\n",
    "    # Splits validation label into multiple slices along batch_axis\n",
    "    # and copy each slice into a context.\n",
    "    label = gluon.utils.split_and_load(batch.label[0], ctx_list=ctx, batch_axis=0)\n",
    "    outputs = []\n",
    "    for x in data:\n",
    "        outputs.append(net(x))\n",
    "    # Updates internal evaluation\n",
    "    metric.update(label, outputs)\n",
    "print('validation acc: %s=%f'%metric.get())\n",
    "assert metric.get()[1] > 0.98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "6CffDtzmE3jv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ut5PAn2tF7Op"
   },
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, we have learned how to use MXNet to solve a standard computer vision problem: classifying images of hand written digits. You have seen how to quickly and easily build, train and evaluate models such as MLP and CNN with MXNet Gluon package."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
