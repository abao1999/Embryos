{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GANomaly.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fy-Of7LeP2Wk",
        "outputId": "22356469-4278-4a65-d541-8b94b9c36f41"
      },
      "source": [
        "# https://stackoverflow.com/questions/48905127/importing-py-files-in-google-colab/48919022\n",
        "import os\n",
        "from google.colab import files\n",
        "# src = list(files.upload().values())[0]\n",
        "# open('utils.py','wb').write(src)\n",
        "# print(os.path.abspath('utils.py'))\n",
        "import utils\n",
        "help(utils)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on module utils:\n",
            "\n",
            "NAME\n",
            "    utils\n",
            "\n",
            "FUNCTIONS\n",
            "    avg_across_z(img, normalize=False)\n",
            "        Returns a new image where each pixel\n",
            "        intensity is the average for that pixel across\n",
            "        all images in the z-stack.\n",
            "    \n",
            "    get_img_at_t(t, img)\n",
            "    \n",
            "    get_max_pixel(embryos, data_path)\n",
            "        Obtains the maximum pixel value across a set of embryos\n",
            "        embryos: subset of p_embryo... train, val, test\n",
            "        data_path: path from which to load processed np embryo data\n",
            "    \n",
            "    get_z_slice(z, img)\n",
            "    \n",
            "    max_across_z(img, normalize=False)\n",
            "        Returns a new image where each pixel\n",
            "        intensity is the maximum for that pixel across\n",
            "        all images in the z-stack.\n",
            "    \n",
            "    middle_z(img)\n",
            "    \n",
            "    min_across_z(img, normalize=False)\n",
            "        Returns a new image where each pixel\n",
            "        intensity is the minimum for that pixel across\n",
            "        all images in the z-stack.\n",
            "    \n",
            "    normalize(img)\n",
            "        Normalizes pixel values across all images in img\n",
            "        to range 0-1.\n",
            "    \n",
            "    save_nps_as_png(embryos, save_path, specs, window=None, normalize='per_embryo', dim=2, pol_subdir=True)\n",
            "        Save dataset in image format, sorted by polarization state\n",
            "        embryos: subset of p_embryo... train, val, test\n",
            "        specs = (data_path, pol_path, video_time_info)\n",
            "        save_path: path to save png to... data_path + {'train', 'val', 'test'}\n",
            "        specs: tuple with data_path (str: processed np embryo data),\n",
            "                          pol_path (str: embryo polarization labels),\n",
            "                          video_time_info (df: info per embryo)\n",
            "        window: number of t steps from first polarized index to ignore\n",
            "        normalize: type of normalization to apply (per_embryo, per_timestep, #)\n",
            "        dim: 2 or 3 (using 2d representation of z-stack or 3d selection of slices)\n",
            "        pol_subdir: whether to save images to \"{save_path}/{pol}/\" or \"{save_path}/\"\n",
            "    \n",
            "    save_nps_subset_z(embryos, save_path, specs, window=None, normalize='per_embryo', mode='middle', n_slices=3, pol_subdir=True)\n",
            "        Save dataset in image format, sorted by polarization state\n",
            "        embryos: subset of p_embryo... train, val, test\n",
            "        specs = (data_path, pol_path, video_time_info)\n",
            "        save_path: path to save png to... data_path + {'train', 'val', 'test'}\n",
            "        specs: tuple with data_path (str: processed np embryo data),\n",
            "                          pol_path (str: embryo polarization labels),\n",
            "                          video_time_info (df: info per embryo)\n",
            "        window: number of t steps from first polarized index to ignore\n",
            "        normalize: type of normalization to apply (per_embryo, per_timestep, #)\n",
            "        mode: min, middle, max... where to start z slices (if middle, get z slices around middle)\n",
            "        n_slices: number of z slices to get\n",
            "        pol_subdir: whether to save images to \"{save_path}/{pol}/\" or \"{save_path}/\"\n",
            "    \n",
            "    split_train_test_val(home_path, embryo_inds)\n",
            "        Splits a set of embryos into train/test/val:\n",
            "        home_path: path to shared drive folder\n",
            "        embryo_inds: list of embryos indices to use\n",
            "    \n",
            "    within_window(embryo_idx, t, window, video_time_info)\n",
            "        Returns if an embryo timestep is close to the 1st polarized time\n",
            "        embryo_idx: index of current embryo (value from 'embryo_index' col)\n",
            "        t: timestep of current\n",
            "        window: number of t steps from first polarized index to ignore\n",
            "        video_time_info: dataframe with labeling/timing information per embryo\n",
            "\n",
            "DATA\n",
            "    CLEAN_IDX = [3, 12, 13, 16, 18, 19, 23, 24, 25, 33, 39, 42, 46, 47, 76...\n",
            "    CLEAN_IDX_FULL = [3, 12, 13, 16, 18, 19, 23, 24, 25, 33, 39, 42, 46, 4...\n",
            "    FULL_IDX = [1, 3, 12, 13, 16, 18, 19, 24, 39, 40, 42, 45, 46, 47, 49, ...\n",
            "    PARTIAL_IDX = [1, 3, 12, 13, 16, 18, 19, 24, 39, 40, 42, 45, 46, 47, 4...\n",
            "\n",
            "FILE\n",
            "    /content/utils.py\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKHDTcsgP5O6"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import os\n",
        "import time\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from IPython import display\n",
        "\n",
        "from __future__ import print_function\n",
        "\n",
        "import torch"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrMcBK2wP8nd",
        "outputId": "1f77b543-2fe3-4c63-a920-55fbc7200a9b"
      },
      "source": [
        "from google.colab import drive   \n",
        "\n",
        "# mount the google drive to my Colab session\n",
        "drive.mount('/content/gdrive')\n",
        "# use the google drive in my Colab session\n",
        "home_path = '/content/gdrive/Shared drives/Embryo_data'\n",
        "print(os.listdir(home_path))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "['mxnet_cnn2d_embryo_58_fine_tune_data_aug_ResNet50_v2_order_random.ipynb', 'Embryo3', 'Embryo12', 'Embryo13', 'Embryo16', 'Embryo19', 'Embryo18', 'Embryo24', 'Embryo39', 'Embryo42', 'Embryo46', 'Embryo47', 'Embryo23', 'Embryo33', 'Embryo25', 'Embryo95', 'Embryo97', 'Embryo96', 'Embryo98', 'Embryo101', 'Embryo99', 'Embryo100', 'Embryo102', 'Embryo76', 'Embryo78', 'Embryo81', 'Embryo79', 'Embryo80', 'Embryo84', 'Embryo85', 'Embryo87', 'Embryo88', 'Embryo92', 'Embryo94', 'Embryo93', 'embryo_info_CS101.xlsx', 'data', 'processed', 'models', 'pix2pix_PyTorch-GAN.ipynb', 'annotation.xlsx', 'Embryo110', 'Embryo109', 'Embryo111', 'Embryo113', 'Embryo112', 'Embryo114', 'Embryo116', 'Embryo115', 'Embryo117', 'Embryo118', 'Embryo119', 'Embryo120', 'Embryo103', 'Embryo104', 'Embryo105', 'Embryo107', 'Embryo106', 'Embryo108', 'pix2pix_output', 'images']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akqQh38mSXv4"
      },
      "source": [
        "import argparse\n",
        "\n",
        "# pylint: disable=C0103,C0301,R0903,W0622\n",
        "\n",
        "class Options():\n",
        "    \"\"\"Options class\n",
        "    Returns:\n",
        "        [argparse]: argparse containing train and test options\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        ##\n",
        "        #\n",
        "        self.parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
        "\n",
        "        ##\n",
        "        # Base\n",
        "        self.parser.add_argument('--dataset', default='cifar10', help='folder | cifar10 | mnist ')\n",
        "        self.parser.add_argument('--dataroot', default='', help='path to dataset')\n",
        "        self.parser.add_argument('--batchsize', type=int, default=64, help='input batch size')\n",
        "        self.parser.add_argument('--workers', type=int, help='number of data loading workers', default=8)\n",
        "        self.parser.add_argument('--droplast', action='store_true', default=True, help='Drop last batch size.')\n",
        "        self.parser.add_argument('--isize', type=int, default=32, help='input image size.')\n",
        "        self.parser.add_argument('--nc', type=int, default=3, help='input image channels')\n",
        "        self.parser.add_argument('--nz', type=int, default=100, help='size of the latent z vector')\n",
        "        self.parser.add_argument('--ngf', type=int, default=64)\n",
        "        self.parser.add_argument('--ndf', type=int, default=64)\n",
        "        self.parser.add_argument('--extralayers', type=int, default=0, help='Number of extra layers on gen and disc')\n",
        "        self.parser.add_argument('--device', type=str, default='gpu', help='Device: gpu | cpu')\n",
        "        self.parser.add_argument('--gpu_ids', type=str, default='0', help='gpu ids: e.g. 0  0,1,2, 0,2. use -1 for CPU')\n",
        "        self.parser.add_argument('--ngpu', type=int, default=1, help='number of GPUs to use')\n",
        "        self.parser.add_argument('--name', type=str, default='experiment_name', help='name of the experiment')\n",
        "        self.parser.add_argument('--model', type=str, default='ganomaly', help='chooses which model to use. ganomaly')\n",
        "        self.parser.add_argument('--display_server', type=str, default=\"http://localhost\", help='visdom server of the web display')\n",
        "        self.parser.add_argument('--display_port', type=int, default=8097, help='visdom port of the web display')\n",
        "        self.parser.add_argument('--display_id', type=int, default=0, help='window id of the web display')\n",
        "        self.parser.add_argument('--display', action='store_true', help='Use visdom.')\n",
        "        self.parser.add_argument('--outf', default='./output', help='folder to output images and model checkpoints')\n",
        "        self.parser.add_argument('--manualseed', default=-1, type=int, help='manual seed')\n",
        "        self.parser.add_argument('--abnormal_class', default='car', help='Anomaly class idx for mnist and cifar datasets')\n",
        "        self.parser.add_argument('--proportion', type=float, default=0.1, help='Proportion of anomalies in test set.')\n",
        "        self.parser.add_argument('--metric', type=str, default='roc', help='Evaluation metric.')\n",
        "\n",
        "        ##\n",
        "        # Train\n",
        "        self.parser.add_argument('--print_freq', type=int, default=100, help='frequency of showing training results on console')\n",
        "        self.parser.add_argument('--save_image_freq', type=int, default=100, help='frequency of saving real and fake images')\n",
        "        self.parser.add_argument('--save_test_images', action='store_true', help='Save test images for demo.')\n",
        "        self.parser.add_argument('--load_weights', action='store_true', help='Load the pretrained weights')\n",
        "        self.parser.add_argument('--resume', default='', help=\"path to checkpoints (to continue training)\")\n",
        "        self.parser.add_argument('--phase', type=str, default='train', help='train, val, test, etc')\n",
        "        self.parser.add_argument('--iter', type=int, default=0, help='Start from iteration i')\n",
        "        self.parser.add_argument('--niter', type=int, default=15, help='number of epochs to train for')\n",
        "        self.parser.add_argument('--beta1', type=float, default=0.5, help='momentum term of adam')\n",
        "        self.parser.add_argument('--lr', type=float, default=0.0002, help='initial learning rate for adam')\n",
        "        self.parser.add_argument('--w_adv', type=float, default=1, help='Adversarial loss weight')\n",
        "        self.parser.add_argument('--w_con', type=float, default=50, help='Reconstruction loss weight')\n",
        "        self.parser.add_argument('--w_enc', type=float, default=1, help='Encoder loss weight.')\n",
        "        self.isTrain = True\n",
        "        self.opt = None\n",
        "\n",
        "    def parse(self):\n",
        "        \"\"\" Parse Arguments.\n",
        "        \"\"\"\n",
        "\n",
        "        self.opt = self.parser.parse_args()\n",
        "        self.opt.isTrain = self.isTrain   # train or test\n",
        "\n",
        "        str_ids = self.opt.gpu_ids.split(',')\n",
        "        self.opt.gpu_ids = []\n",
        "        for str_id in str_ids:\n",
        "            id = int(str_id)\n",
        "            if id >= 0:\n",
        "                self.opt.gpu_ids.append(id)\n",
        "\n",
        "        # set gpu ids\n",
        "        if self.opt.device == 'gpu':\n",
        "            torch.cuda.set_device(self.opt.gpu_ids[0])\n",
        "\n",
        "        args = vars(self.opt)\n",
        "\n",
        "        # print('------------ Options -------------')\n",
        "        # for k, v in sorted(args.items()):\n",
        "        #     print('%s: %s' % (str(k), str(v)))\n",
        "        # print('-------------- End ----------------')\n",
        "\n",
        "        # save to the disk\n",
        "        if self.opt.name == 'experiment_name':\n",
        "            self.opt.name = \"%s/%s\" % (self.opt.model, self.opt.dataset)\n",
        "        expr_dir = os.path.join(self.opt.outf, self.opt.name, 'train')\n",
        "        test_dir = os.path.join(self.opt.outf, self.opt.name, 'test')\n",
        "\n",
        "        if not os.path.isdir(expr_dir):\n",
        "            os.makedirs(expr_dir)\n",
        "        if not os.path.isdir(test_dir):\n",
        "            os.makedirs(test_dir)\n",
        "\n",
        "        file_name = os.path.join(expr_dir, 'opt.txt')\n",
        "        with open(file_name, 'wt') as opt_file:\n",
        "            opt_file.write('------------ Options -------------\\n')\n",
        "            for k, v in sorted(args.items()):\n",
        "                opt_file.write('%s: %s\\n' % (str(k), str(v)))\n",
        "            opt_file.write('-------------- End ----------------\\n')\n",
        "        return self.opt"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quXDabPVQ4ZR"
      },
      "source": [
        "\"\"\"\n",
        "LOAD DATA from file.\n",
        "\"\"\"\n",
        "\n",
        "# pylint: disable=C0301,E1101,W0622,C0103,R0902,R0915\n",
        "\n",
        "##\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import torchvision.datasets as datasets\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "##\n",
        "def load_data(opt):\n",
        "    \"\"\" Load Data\n",
        "    Args:\n",
        "        opt ([type]): Argument Parser\n",
        "    Raises:\n",
        "        IOError: Cannot Load Dataset\n",
        "    Returns:\n",
        "        [type]: dataloader\n",
        "    \"\"\"\n",
        "\n",
        "    ##\n",
        "    # LOAD DATA SET\n",
        "    if opt.dataroot == '':\n",
        "        opt.dataroot = './data/{}'.format(opt.dataset)\n",
        "\n",
        "    if opt.dataset in ['cifar10']:\n",
        "        splits = ['train', 'test']\n",
        "        drop_last_batch = {'train': True, 'test': False}\n",
        "        shuffle = {'train': True, 'test': False}\n",
        "\n",
        "        transform = transforms.Compose(\n",
        "            [\n",
        "                transforms.Resize(opt.isize),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        classes = {\n",
        "            'plane': 0, 'car': 1, 'bird': 2, 'cat': 3, 'deer': 4,\n",
        "            'dog': 5, 'frog': 6, 'horse': 7, 'ship': 8, 'truck': 9\n",
        "        }\n",
        "\n",
        "        dataset = {}\n",
        "        dataset['train'] = CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "        dataset['test'] = CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "        dataset['train'].data, dataset['train'].targets, \\\n",
        "        dataset['test'].data, dataset['test'].targets = get_cifar_anomaly_dataset(\n",
        "            trn_img=dataset['train'].data,\n",
        "            trn_lbl=dataset['train'].targets,\n",
        "            tst_img=dataset['test'].data,\n",
        "            tst_lbl=dataset['test'].targets,\n",
        "            abn_cls_idx=classes[opt.abnormal_class],\n",
        "            manualseed=opt.manualseed\n",
        "        )\n",
        "\n",
        "        dataloader = {x: torch.utils.data.DataLoader(dataset=dataset[x],\n",
        "                                                     batch_size=opt.batchsize,\n",
        "                                                     shuffle=shuffle[x],\n",
        "                                                     num_workers=int(opt.workers),\n",
        "                                                     drop_last=drop_last_batch[x],\n",
        "                                                     worker_init_fn=(None if opt.manualseed == -1\n",
        "                                                     else lambda x: np.random.seed(opt.manualseed)))\n",
        "                      for x in splits}\n",
        "        return dataloader\n",
        "\n",
        "    elif opt.dataset in ['mnist']:\n",
        "        opt.abnormal_class = int(opt.abnormal_class)\n",
        "\n",
        "        splits = ['train', 'test']\n",
        "        drop_last_batch = {'train': True, 'test': False}\n",
        "        shuffle = {'train': True, 'test': True}\n",
        "\n",
        "        transform = transforms.Compose(\n",
        "            [\n",
        "                transforms.Resize(opt.isize),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize((0.1307,), (0.3081,))\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        dataset = {}\n",
        "        dataset['train'] = MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "        dataset['test'] = MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "        dataset['train'].data, dataset['train'].targets, \\\n",
        "        dataset['test'].data, dataset['test'].targets = get_mnist_anomaly_dataset(\n",
        "            trn_img=dataset['train'].data,\n",
        "            trn_lbl=dataset['train'].targets,\n",
        "            tst_img=dataset['test'].data,\n",
        "            tst_lbl=dataset['test'].targets,\n",
        "            abn_cls_idx=opt.abnormal_class,\n",
        "            manualseed=opt.manualseed\n",
        "        )\n",
        "\n",
        "        dataloader = {x: torch.utils.data.DataLoader(dataset=dataset[x],\n",
        "                                                     batch_size=opt.batchsize,\n",
        "                                                     shuffle=shuffle[x],\n",
        "                                                     num_workers=int(opt.workers),\n",
        "                                                     drop_last=drop_last_batch[x],\n",
        "                                                     worker_init_fn=(None if opt.manualseed == -1\n",
        "                                                     else lambda x: np.random.seed(opt.manualseed)))\n",
        "                      for x in splits}\n",
        "        return dataloader\n",
        "\n",
        "    elif opt.dataset in ['mnist2']:\n",
        "        opt.abnormal_class = int(opt.abnormal_class)\n",
        "\n",
        "        splits = ['train', 'test']\n",
        "        drop_last_batch = {'train': True, 'test': False}\n",
        "        shuffle = {'train': True, 'test': True}\n",
        "\n",
        "        transform = transforms.Compose(\n",
        "            [\n",
        "                transforms.Resize(opt.isize),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize((0.1307,), (0.3081,))\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        dataset = {}\n",
        "        dataset['train'] = MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "        dataset['test'] = MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "        dataset['train'].data, dataset['train'].targets, \\\n",
        "        dataset['test'].data, dataset['test'].targets = get_mnist2_anomaly_dataset(\n",
        "            trn_img=dataset['train'].data,\n",
        "            trn_lbl=dataset['train'].targets,\n",
        "            tst_img=dataset['test'].data,\n",
        "            tst_lbl=dataset['test'].targets,\n",
        "            nrm_cls_idx=opt.abnormal_class,\n",
        "            proportion=opt.proportion,\n",
        "            manualseed=opt.manualseed\n",
        "        )\n",
        "\n",
        "        dataloader = {x: torch.utils.data.DataLoader(dataset=dataset[x],\n",
        "                                                     batch_size=opt.batchsize,\n",
        "                                                     shuffle=shuffle[x],\n",
        "                                                     num_workers=int(opt.workers),\n",
        "                                                     drop_last=drop_last_batch[x],\n",
        "                                                     worker_init_fn=(None if opt.manualseed == -1\n",
        "                                                     else lambda x: np.random.seed(opt.manualseed)))\n",
        "                      for x in splits}\n",
        "        return dataloader\n",
        "\n",
        "    else:\n",
        "        splits = ['train', 'test']\n",
        "        drop_last_batch = {'train': True, 'test': False}\n",
        "        shuffle = {'train': True, 'test': True}\n",
        "        # transform = transforms.Compose([transforms.Resize(opt.isize),\n",
        "        #                                 transforms.CenterCrop(opt.isize),\n",
        "        #                                 transforms.ToTensor(),\n",
        "        #                                 transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), ])\n",
        "\n",
        "        transform = transforms.Compose([\n",
        "            transforms.Resize(600),\n",
        "            transforms.CenterCrop(512),\n",
        "\n",
        "            transforms.RandomHorizontalFlip(), # Randomly flip the image horizontally\n",
        "            transforms.RandomVerticalFlip(),\n",
        "            # transforms.RandomLighting(0.1), # Add AlexNet-style PCA-based noise to an image... need to implement: https://github.com/facebook/fb.resnet.torch/blob/master/datasets/transforms.lua#L183\n",
        "            # transforms.functional.adjust_contrast(contrast_factor=0.9 + np.random.random_sample()*0.2),\n",
        "            transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "        dataset = {x: ImageFolder(os.path.join(opt.dataroot, x), transform) for x in splits}\n",
        "        dataloader = {x: torch.utils.data.DataLoader(dataset=dataset[x],\n",
        "                                                     batch_size=opt.batchsize,\n",
        "                                                     shuffle=shuffle[x],\n",
        "                                                     num_workers=int(opt.workers),\n",
        "                                                     drop_last=drop_last_batch[x],\n",
        "                                                     worker_init_fn=(None if opt.manualseed == -1\n",
        "                                                     else lambda x: np.random.seed(opt.manualseed)))\n",
        "                      for x in splits}\n",
        "        return dataloader\n",
        "\n",
        "##\n",
        "def get_cifar_anomaly_dataset(trn_img, trn_lbl, tst_img, tst_lbl, abn_cls_idx=0, manualseed=-1):\n",
        "    \"\"\"[summary]\n",
        "    Arguments:\n",
        "        trn_img {np.array} -- Training images\n",
        "        trn_lbl {np.array} -- Training labels\n",
        "        tst_img {np.array} -- Test     images\n",
        "        tst_lbl {np.array} -- Test     labels\n",
        "    Keyword Arguments:\n",
        "        abn_cls_idx {int} -- Anomalous class index (default: {0})\n",
        "    Returns:\n",
        "        [np.array] -- New training-test images and labels.\n",
        "    \"\"\"\n",
        "    # Convert train-test labels into numpy array.\n",
        "    trn_lbl = np.array(trn_lbl)\n",
        "    tst_lbl = np.array(tst_lbl)\n",
        "\n",
        "    # --\n",
        "    # Find idx, img, lbl for abnormal and normal on org dataset.\n",
        "    nrm_trn_idx = np.where(trn_lbl != abn_cls_idx)[0]\n",
        "    abn_trn_idx = np.where(trn_lbl == abn_cls_idx)[0]\n",
        "    nrm_trn_img = trn_img[nrm_trn_idx]    # Normal training images\n",
        "    abn_trn_img = trn_img[abn_trn_idx]    # Abnormal training images\n",
        "    nrm_trn_lbl = trn_lbl[nrm_trn_idx]    # Normal training labels\n",
        "    abn_trn_lbl = trn_lbl[abn_trn_idx]    # Abnormal training labels.\n",
        "\n",
        "    nrm_tst_idx = np.where(tst_lbl != abn_cls_idx)[0]\n",
        "    abn_tst_idx = np.where(tst_lbl == abn_cls_idx)[0]\n",
        "    nrm_tst_img = tst_img[nrm_tst_idx]    # Normal training images\n",
        "    abn_tst_img = tst_img[abn_tst_idx]    # Abnormal training images.\n",
        "    nrm_tst_lbl = tst_lbl[nrm_tst_idx]    # Normal training labels\n",
        "    abn_tst_lbl = tst_lbl[abn_tst_idx]    # Abnormal training labels.\n",
        "\n",
        "    # --\n",
        "    # Assign labels to normal (0) and abnormals (1)\n",
        "    nrm_trn_lbl[:] = 0\n",
        "    nrm_tst_lbl[:] = 0\n",
        "    abn_trn_lbl[:] = 1\n",
        "    abn_tst_lbl[:] = 1\n",
        "\n",
        "    # --\n",
        "    if manualseed != -1:\n",
        "        # Random seed.\n",
        "        # Concatenate the original train and test sets.\n",
        "        nrm_img = np.concatenate((nrm_trn_img, nrm_tst_img), axis=0)\n",
        "        nrm_lbl = np.concatenate((nrm_trn_lbl, nrm_tst_lbl), axis=0)\n",
        "        abn_img = np.concatenate((abn_trn_img, abn_tst_img), axis=0)\n",
        "        abn_lbl = np.concatenate((abn_trn_lbl, abn_tst_lbl), axis=0)\n",
        "\n",
        "        # Split the normal data into the new train and tests.\n",
        "        idx = np.arange(len(nrm_lbl))\n",
        "        np.random.seed(manualseed)\n",
        "        np.random.shuffle(idx)\n",
        "\n",
        "        nrm_trn_len = int(len(idx) * 0.80)\n",
        "        nrm_trn_idx = idx[:nrm_trn_len]\n",
        "        nrm_tst_idx = idx[nrm_trn_len:]\n",
        "\n",
        "        nrm_trn_img = nrm_img[nrm_trn_idx]\n",
        "        nrm_trn_lbl = nrm_lbl[nrm_trn_idx]\n",
        "        nrm_tst_img = nrm_img[nrm_tst_idx]\n",
        "        nrm_tst_lbl = nrm_lbl[nrm_tst_idx]\n",
        "\n",
        "    # Create new anomaly dataset based on the following data structure:\n",
        "    # - anomaly dataset\n",
        "    #   . -> train\n",
        "    #        . -> normal\n",
        "    #   . -> test\n",
        "    #        . -> normal\n",
        "    #        . -> abnormal\n",
        "    new_trn_img = np.copy(nrm_trn_img)\n",
        "    new_trn_lbl = np.copy(nrm_trn_lbl)\n",
        "    new_tst_img = np.concatenate((nrm_tst_img, abn_trn_img, abn_tst_img), axis=0)\n",
        "    new_tst_lbl = np.concatenate((nrm_tst_lbl, abn_trn_lbl, abn_tst_lbl), axis=0)\n",
        "\n",
        "    return new_trn_img, new_trn_lbl, new_tst_img, new_tst_lbl\n",
        "\n",
        "##\n",
        "def get_mnist_anomaly_dataset(trn_img, trn_lbl, tst_img, tst_lbl, abn_cls_idx=0, manualseed=-1):\n",
        "    \"\"\"[summary]\n",
        "    Arguments:\n",
        "        trn_img {np.array} -- Training images\n",
        "        trn_lbl {np.array} -- Training labels\n",
        "        tst_img {np.array} -- Test     images\n",
        "        tst_lbl {np.array} -- Test     labels\n",
        "    Keyword Arguments:\n",
        "        abn_cls_idx {int} -- Anomalous class index (default: {0})\n",
        "    Returns:\n",
        "        [np.array] -- New training-test images and labels.\n",
        "    \"\"\"\n",
        "    # --\n",
        "    # Find normal abnormal indexes.\n",
        "    nrm_trn_idx = torch.from_numpy(np.where(trn_lbl.numpy() != abn_cls_idx)[0])\n",
        "    abn_trn_idx = torch.from_numpy(np.where(trn_lbl.numpy() == abn_cls_idx)[0])\n",
        "    nrm_tst_idx = torch.from_numpy(np.where(tst_lbl.numpy() != abn_cls_idx)[0])\n",
        "    abn_tst_idx = torch.from_numpy(np.where(tst_lbl.numpy() == abn_cls_idx)[0])\n",
        "\n",
        "    # --\n",
        "    # Find normal and abnormal images\n",
        "    nrm_trn_img = trn_img[nrm_trn_idx]    # Normal training images\n",
        "    abn_trn_img = trn_img[abn_trn_idx]    # Abnormal training images.\n",
        "    nrm_tst_img = tst_img[nrm_tst_idx]    # Normal training images\n",
        "    abn_tst_img = tst_img[abn_tst_idx]    # Abnormal training images.\n",
        "\n",
        "    # --\n",
        "    # Find normal and abnormal labels.\n",
        "    nrm_trn_lbl = trn_lbl[nrm_trn_idx]    # Normal training labels\n",
        "    abn_trn_lbl = trn_lbl[abn_trn_idx]    # Abnormal training labels.\n",
        "    nrm_tst_lbl = tst_lbl[nrm_tst_idx]    # Normal training labels\n",
        "    abn_tst_lbl = tst_lbl[abn_tst_idx]    # Abnormal training labels.\n",
        "\n",
        "    # --\n",
        "    # Assign labels to normal (0) and abnormals (1)\n",
        "    nrm_trn_lbl[:] = 0\n",
        "    nrm_tst_lbl[:] = 0\n",
        "    abn_trn_lbl[:] = 1\n",
        "    abn_tst_lbl[:] = 1\n",
        "\n",
        "    # --\n",
        "    if manualseed != -1:\n",
        "        # Random seed.\n",
        "        # Concatenate the original train and test sets.\n",
        "        nrm_img = torch.cat((nrm_trn_img, nrm_tst_img), dim=0)\n",
        "        nrm_lbl = torch.cat((nrm_trn_lbl, nrm_tst_lbl), dim=0)\n",
        "        abn_img = torch.cat((abn_trn_img, abn_tst_img), dim=0)\n",
        "        abn_lbl = torch.cat((abn_trn_lbl, abn_tst_lbl), dim=0)\n",
        "\n",
        "        # Split the normal data into the new train and tests.\n",
        "        idx = np.arange(len(nrm_lbl))\n",
        "        np.random.seed(manualseed)\n",
        "        np.random.shuffle(idx)\n",
        "\n",
        "        nrm_trn_len = int(len(idx) * 0.80)\n",
        "        nrm_trn_idx = idx[:nrm_trn_len]\n",
        "        nrm_tst_idx = idx[nrm_trn_len:]\n",
        "\n",
        "        nrm_trn_img = nrm_img[nrm_trn_idx]\n",
        "        nrm_trn_lbl = nrm_lbl[nrm_trn_idx]\n",
        "        nrm_tst_img = nrm_img[nrm_tst_idx]\n",
        "        nrm_tst_lbl = nrm_lbl[nrm_tst_idx]\n",
        "\n",
        "    # Create new anomaly dataset based on the following data structure:\n",
        "    new_trn_img = nrm_trn_img.clone()\n",
        "    new_trn_lbl = nrm_trn_lbl.clone()\n",
        "    new_tst_img = torch.cat((nrm_tst_img, abn_trn_img, abn_tst_img), dim=0)\n",
        "    new_tst_lbl = torch.cat((nrm_tst_lbl, abn_trn_lbl, abn_tst_lbl), dim=0)\n",
        "\n",
        "    return new_trn_img, new_trn_lbl, new_tst_img, new_tst_lbl\n",
        "\n",
        "##\n",
        "def get_mnist2_anomaly_dataset(trn_img, trn_lbl, tst_img, tst_lbl, nrm_cls_idx=0, proportion=0.5,\n",
        "                               manualseed=-1):\n",
        "    \"\"\" Create mnist 2 anomaly dataset.\n",
        "    Arguments:\n",
        "        trn_img {np.array} -- Training images\n",
        "        trn_lbl {np.array} -- Training labels\n",
        "        tst_img {np.array} -- Test     images\n",
        "        tst_lbl {np.array} -- Test     labels\n",
        "    Keyword Arguments:\n",
        "        nrm_cls_idx {int} -- Anomalous class index (default: {0})\n",
        "    Returns:\n",
        "        [tensor] -- New training-test images and labels.\n",
        "    \"\"\"\n",
        "    # Seed for deterministic behavior\n",
        "    if manualseed != -1:\n",
        "        torch.manual_seed(manualseed)\n",
        "\n",
        "    # --\n",
        "    # Find normal abnormal indexes.\n",
        "    # TODO: PyTorch v0.4 has torch.where function\n",
        "    nrm_trn_idx = torch.from_numpy(np.where(trn_lbl.numpy() == nrm_cls_idx)[0])\n",
        "    abn_trn_idx = torch.from_numpy(np.where(trn_lbl.numpy() != nrm_cls_idx)[0])\n",
        "    nrm_tst_idx = torch.from_numpy(np.where(tst_lbl.numpy() == nrm_cls_idx)[0])\n",
        "    abn_tst_idx = torch.from_numpy(np.where(tst_lbl.numpy() != nrm_cls_idx)[0])\n",
        "\n",
        "    # Get n percent of the abnormal samples.\n",
        "    abn_tst_idx = abn_tst_idx[torch.randperm(len(abn_tst_idx))]\n",
        "    abn_tst_idx = abn_tst_idx[:int(len(abn_tst_idx) * proportion)]\n",
        "\n",
        "\n",
        "    # --\n",
        "    # Find normal and abnormal images\n",
        "    nrm_trn_img = trn_img[nrm_trn_idx]    # Normal training images\n",
        "    abn_trn_img = trn_img[abn_trn_idx]    # Abnormal training images.\n",
        "    nrm_tst_img = tst_img[nrm_tst_idx]    # Normal training images\n",
        "    abn_tst_img = tst_img[abn_tst_idx]    # Abnormal training images.\n",
        "\n",
        "    # --\n",
        "    # Find normal and abnormal labels.\n",
        "    nrm_trn_lbl = trn_lbl[nrm_trn_idx]    # Normal training labels\n",
        "    abn_trn_lbl = trn_lbl[abn_trn_idx]    # Abnormal training labels.\n",
        "    nrm_tst_lbl = tst_lbl[nrm_tst_idx]    # Normal training labels\n",
        "    abn_tst_lbl = tst_lbl[abn_tst_idx]    # Abnormal training labels.\n",
        "\n",
        "    # --\n",
        "    # Assign labels to normal (0) and abnormals (1)\n",
        "    nrm_trn_lbl[:] = 0\n",
        "    nrm_tst_lbl[:] = 0\n",
        "    abn_trn_lbl[:] = 1\n",
        "    abn_tst_lbl[:] = 1\n",
        "\n",
        "    # Create new anomaly dataset based on the following data structure:\n",
        "    new_trn_img = nrm_trn_img.clone()\n",
        "    new_trn_lbl = nrm_trn_lbl.clone()\n",
        "    new_tst_img = torch.cat((nrm_tst_img, abn_tst_img), dim=0)\n",
        "    new_tst_lbl = torch.cat((nrm_tst_lbl, abn_tst_lbl), dim=0)\n",
        "\n",
        "    return new_trn_img, new_trn_lbl, new_tst_img, new_tst_lbl"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LarbWRjdTQap",
        "outputId": "b8684bde-5c70-4fad-ff2c-ec5a429bbab6"
      },
      "source": [
        "opt = Options().parser.parse_args(\"\")\n",
        "# args = Options.parse_args(\"\")\n",
        "opt.abnormal_class = '1'\n",
        "opt.dataroot = f'{home_path}/processed/fluo_data/max'\n",
        "opt.dataset = 'embryo1'\n",
        "opt.batchsize=5\n",
        "opt.niter = 25\n",
        "opt.model = 'ganomaly'\n",
        "opt.ngpu = 1\n",
        "opt.isize = 512\n",
        "opt.display = False\n",
        "opt.print_freq = 100\n",
        "opt.save_image_freq = 100\n",
        "opt.save_test_images = False\n",
        "opt.workers = 1\n",
        "opt.droplast = True\n",
        "opt.isTrain = True\n",
        "print(opt)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(abnormal_class='1', batchsize=5, beta1=0.5, dataroot='/content/gdrive/Shared drives/Embryo_data/processed/fluo_data/max', dataset='embryo1', device='gpu', display=False, display_id=0, display_port=8097, display_server='http://localhost', droplast=True, extralayers=0, gpu_ids='0', isTrain=True, isize=512, iter=0, load_weights=False, lr=0.0002, manualseed=-1, metric='roc', model='ganomaly', name='experiment_name', nc=3, ndf=64, ngf=64, ngpu=1, niter=25, nz=100, outf='./output', phase='train', print_freq=100, proportion=0.1, resume='', save_image_freq=100, save_test_images=False, w_adv=1, w_con=50, w_enc=1, workers=1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wp5Z7zfXQLgh"
      },
      "source": [
        "train_loader = load_data(opt)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9gdX2WCWj0D"
      },
      "source": [
        "# # get some random training images\n",
        "# dataiter = iter(train_loader)\n",
        "# # next(dataiter)\n",
        "# images = next(dataiter)\n",
        "# print(images)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMBbp-reXSAH"
      },
      "source": [
        "from lib.model import Ganomaly"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCEeyQXeY1B8"
      },
      "source": [
        "# !pip install visdom"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "qy63ijXGYnTK",
        "outputId": "f29d0892-266d-43ff-bfc0-34edffa86764"
      },
      "source": [
        "model = Ganomaly(opt, train_loader)\n",
        "model.train()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/448 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">> Training model Ganomaly.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-73a85667825f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGanomaly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/lib/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mniter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;31m# Train for one epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_auc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/lib/model.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0;31m# self.optimize()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_steps\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_freq\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/lib/model.py\u001b[0m in \u001b[0;36moptimize_params\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;31m# netg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_g\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward_g\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_g\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/lib/model.py\u001b[0m in \u001b[0;36mbackward_g\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \"\"\" Backpropagate through netG\n\u001b[1;32m    317\u001b[0m         \"\"\"\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merr_g_adv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml_adv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merr_g_con\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml_con\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merr_g_enc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml_enc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatent_o\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatent_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/lib/networks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    418\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    419\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 420\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 80.00 MiB (GPU 0; 14.73 GiB total capacity; 13.75 GiB already allocated; 13.88 MiB free; 13.78 GiB reserved in total by PyTorch)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fddZZmwWYrZi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}