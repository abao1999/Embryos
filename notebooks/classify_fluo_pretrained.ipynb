{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 358,
     "status": "ok",
     "timestamp": 1603387548521,
     "user": {
      "displayName": "Christine Yu",
      "photoUrl": "",
      "userId": "17254532280477988261"
     },
     "user_tz": 420
    },
    "id": "H29TGLErCP5r"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "executionInfo": {
     "elapsed": 4999,
     "status": "ok",
     "timestamp": 1603387553885,
     "user": {
      "displayName": "Christine Yu",
      "photoUrl": "",
      "userId": "17254532280477988261"
     },
     "user_tz": 420
    },
    "id": "xVkEhqIhCeLH",
    "outputId": "17f5fa29-b8cc-4a28-9466-6c267edd5839"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mxnet-cu101 in /usr/local/lib/python3.6/dist-packages (1.7.0)\n",
      "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu101) (0.8.4)\n",
      "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu101) (1.18.5)\n",
      "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu101) (2.23.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu101) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu101) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu101) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu101) (2.10)\n",
      "Requirement already satisfied: gluoncv in /usr/local/lib/python3.6/dist-packages (0.8.0)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from gluoncv) (7.0.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from gluoncv) (3.2.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from gluoncv) (1.18.5)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gluoncv) (2.23.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from gluoncv) (4.41.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gluoncv) (1.4.1)\n",
      "Requirement already satisfied: portalocker in /usr/local/lib/python3.6/dist-packages (from gluoncv) (2.0.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->gluoncv) (1.2.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->gluoncv) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->gluoncv) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->gluoncv) (0.10.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gluoncv) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gluoncv) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gluoncv) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gluoncv) (2.10)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib->gluoncv) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install mxnet-cu101\n",
    "!pip install gluoncv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 2072,
     "status": "ok",
     "timestamp": 1603387556981,
     "user": {
      "displayName": "Christine Yu",
      "photoUrl": "",
      "userId": "17254532280477988261"
     },
     "user_tz": 420
    },
    "id": "zG53T9hI2nlC"
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "import numpy as np\n",
    "import os, time, shutil\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from mxnet import gluon, image, init, nd\n",
    "from mxnet import autograd as ag\n",
    "from mxnet.gluon import nn\n",
    "from mxnet.gluon.data.vision import transforms\n",
    "from gluoncv.utils import makedirs\n",
    "from gluoncv.model_zoo import get_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UGh49iIJCP5u"
   },
   "source": [
    "# 4. Transfer Learning with Your Own Image Dataset\n",
    "\n",
    "Dataset size is a big factor in the performance of deep learning models.\n",
    "``ImageNet`` has over one million labeled images, but\n",
    "we often don't have so much labeled data in other domains.\n",
    "Training a deep learning models on small datasets may lead to severe overfitting.\n",
    "\n",
    "Transfer learning is a technique that addresses this problem.\n",
    "The idea is simple: we can start training with a pre-trained model,\n",
    "instead of starting from scratch.\n",
    "As Isaac Newton said, \"If I have seen further it is by standing on the\n",
    "shoulders of Giants\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "executionInfo": {
     "elapsed": 387,
     "status": "ok",
     "timestamp": 1603387557849,
     "user": {
      "displayName": "Christine Yu",
      "photoUrl": "",
      "userId": "17254532280477988261"
     },
     "user_tz": 420
    },
    "id": "VCMW-mPvwrcw",
    "outputId": "1245c909-927c-42aa-89fa-28d380ab764e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
      "['cs101', 'Getting started.pdf', 'Colab Notebooks', 'embryo_13_fluo_sequence.mp4', 'embryo_13_fluo_slice.mp4', 'embryo_13_bf_slice.mp4', 'embryo_13_bf_sequence.mp4', 'hi', 'embryo data.gsheet', 'classify_fluo_pretrained.ipynb']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from google.colab import files, drive   \n",
    "import pandas as pd\n",
    "\n",
    "# mount the google drive to my Colab session\n",
    "drive.mount('/content/gdrive')\n",
    "# use the google drive in my Colab session\n",
    "print(os.listdir('/content/gdrive/My Drive/'))\n",
    "\n",
    "home_path = '/content/gdrive/My Drive/cs101'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "executionInfo": {
     "elapsed": 351,
     "status": "ok",
     "timestamp": 1603387560338,
     "user": {
      "displayName": "Christine Yu",
      "photoUrl": "",
      "userId": "17254532280477988261"
     },
     "user_tz": 420
    },
    "id": "jarQcT4Myge3",
    "outputId": "59fa1a35-e364-4aa3-a570-ded2169cba98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usable_index\n",
      "1      21.0\n",
      "3      21.0\n",
      "12    143.0\n",
      "13    143.0\n",
      "16    143.0\n",
      "18    143.0\n",
      "19    143.0\n",
      "24     21.0\n",
      "39     21.0\n",
      "40     21.0\n",
      "42     21.0\n",
      "45     21.0\n",
      "46     21.0\n",
      "47     21.0\n",
      "49     21.0\n",
      "50     21.0\n",
      "52     21.0\n",
      "53     21.0\n",
      "Name: t_num, dtype: float64\n",
      "[1, 3, 39, 18, 13, 47, 52, 50, 45, 12, 40, 53]\n",
      "[16, 46, 24]\n",
      "[42, 49, 19]\n"
     ]
    }
   ],
   "source": [
    "# Fixing the random seed\n",
    "mx.random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Available data\n",
    "embryo_inds = [1, 3, 12, 13, 16, 18, 19, 24, 39, 40, 42, 45, 46, 47, 49, 50, 52, 53]\n",
    "\n",
    "# Load info about videos\n",
    "video_time_info = pd.read_excel(f'{home_path}/video_data_time_info_CS101.xlsx', index_col=0, header=0, na_values=['NaN','NAN'], usecols=['usable_index', 'first_pol_time', 't_num'])  \n",
    "video_time_info.dropna(inplace=True, subset=['first_pol_time'])\n",
    "print(video_time_info.loc[embryo_inds, 't_num'])\n",
    "\n",
    "# Directory of the processed *.npy files\n",
    "processed_path = f'{home_path}/processed'\n",
    "polar_processed_path = f'{processed_path}/polarization'\n",
    "\n",
    "p = np.random.permutation(len(embryo_inds))\n",
    "p_embryo = [embryo_inds[i] for i in p]\n",
    "t_num = list(video_time_info.loc[embryo_inds, 't_num'])\n",
    "t_num_random = list(video_time_info.loc[p_embryo, 't_num'])\n",
    "\n",
    "instance_cum_random = np.cumsum(t_num_random)\n",
    "test_split_point = instance_cum_random[-1]*0.83\n",
    "temp = abs(instance_cum_random-test_split_point)\n",
    "test_idx = np.argmin(temp)\n",
    "\n",
    "val_split_point = instance_cum_random[-1]*0.7\n",
    "temp = abs(instance_cum_random-val_split_point)\n",
    "val_idx = np.argmin(temp)\n",
    "\n",
    "# normal t list grouped by embryo\n",
    "# instance_cum = list(np.cumsum(t_num))\n",
    "# instance_cum = [0] + instance_cum\n",
    "# t_list = {};\n",
    "# for k in range(len(instance_cum)-1):\n",
    "#     t_list[k] = list(range(int(instance_cum[k]),int(instance_cum[k+1])))\n",
    "# # randomized t list grouped by embryo \n",
    "# train_list_random = []\n",
    "# for k in p[0:idx]:\n",
    "#     train_list_random += t_list[k]\n",
    "\n",
    "# test_list_random = []\n",
    "# for k in p[idx+1:]:\n",
    "#     test_list_random += t_list[k]\n",
    "\n",
    "# print(train_list_random)\n",
    "# print(test_list_random)\n",
    "# Output \n",
    "\n",
    "train_embryos = p_embryo[:val_idx]\n",
    "val_embryos = p_embryo[val_idx:test_idx]\n",
    "test_embryos = p_embryo[test_idx:]\n",
    "print(train_embryos)\n",
    "print(val_embryos)\n",
    "print(test_embryos)\n",
    "\n",
    "data_path = f'{processed_path}/fluo_data/middle'\n",
    "pol_path = f'{processed_path}/polarization'\n",
    "train_path = os.path.join(data_path, 'train')\n",
    "val_path = os.path.join(data_path, 'val')\n",
    "test_path = os.path.join(data_path, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "executionInfo": {
     "elapsed": 30087,
     "status": "ok",
     "timestamp": 1603387438924,
     "user": {
      "displayName": "Christine Yu",
      "photoUrl": "",
      "userId": "17254532280477988261"
     },
     "user_tz": 420
    },
    "id": "4DeDWzqZ1xKt",
    "outputId": "8619ab67-baae-437a-b64a-507e67003ff6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "3\n",
      "39\n",
      "18\n",
      "13\n",
      "47\n",
      "52\n",
      "50\n",
      "45\n",
      "12\n",
      "40\n",
      "53\n",
      "16\n",
      "46\n",
      "24\n",
      "42\n",
      "49\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "# Actually create the images\n",
    "for i in range(len(train_embryos)):\n",
    "  embryo_idx = train_embryos[i]\n",
    "  embryo_path = f'{data_path}/embryo_{embryo_idx}.npy'\n",
    "  embryo_pol_path = f'{pol_path}/embryo_{embryo_idx}.npy'\n",
    "  embryo = np.load(embryo_path)\n",
    "  embryo_pol = np.squeeze(np.load(embryo_pol_path)).astype(int)\n",
    "  embryo = embryo.astype(np.float64) / np.max(embryo) # normalize the data to 0 - 1\n",
    "  embryo = 255 * embryo # Now scale by 255\n",
    "  embryo = embryo.astype(np.uint8)\n",
    "  print(embryo_idx)\n",
    "  for t in range(np.shape(embryo)[2]):\n",
    "    pol = embryo_pol[t]\n",
    "    img = Image.fromarray(embryo[:,:,t], 'L')\n",
    "    img_path = f'{train_path}/{pol}/embryo_{embryo_idx}_{t}.png'\n",
    "    img.save(img_path)\n",
    "\n",
    "for i in range(len(val_embryos)):\n",
    "  embryo_idx = val_embryos[i]\n",
    "  embryo_path = f'{data_path}/embryo_{embryo_idx}.npy'\n",
    "  embryo_pol_path = f'{pol_path}/embryo_{embryo_idx}.npy'\n",
    "  embryo = np.load(embryo_path)\n",
    "  embryo_pol = np.squeeze(np.load(embryo_pol_path)).astype(int)\n",
    "  embryo = embryo.astype(np.float64) / np.max(embryo) # normalize the data to 0 - 1\n",
    "  embryo = 255 * embryo # Now scale by 255\n",
    "  embryo = embryo.astype(np.uint8)\n",
    "  print(embryo_idx)\n",
    "  for t in range(np.shape(embryo)[2]):\n",
    "    pol = embryo_pol[t]\n",
    "    img = Image.fromarray(embryo[:,:,t], 'L')\n",
    "    img_path = f'{val_path}/{pol}/embryo_{embryo_idx}_{t}.png'\n",
    "    img.save(img_path)\n",
    "\n",
    "for i in range(len(test_embryos)):\n",
    "  embryo_idx = test_embryos[i]\n",
    "  embryo_path = f'{data_path}/embryo_{embryo_idx}.npy'\n",
    "  embryo_pol_path = f'{pol_path}/embryo_{embryo_idx}.npy'\n",
    "  embryo = np.load(embryo_path)\n",
    "  embryo_pol = np.squeeze(np.load(embryo_pol_path)).astype(int)\n",
    "  embryo = embryo.astype(np.float64) / np.max(embryo) # normalize the data to 0 - 1\n",
    "  embryo = 255 * embryo # Now scale by 255\n",
    "  embryo = embryo.astype(np.uint8)\n",
    "  print(embryo_idx)\n",
    "  for t in range(np.shape(embryo)[2]):\n",
    "    pol = embryo_pol[t]\n",
    "    img = Image.fromarray(embryo[:,:,t], 'L')\n",
    "    img_path = f'{test_path}/{pol}/embryo_{embryo_idx}_{t}.png'\n",
    "    img.save(img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mhHeN0l4CP5y"
   },
   "source": [
    "## Hyperparameters\n",
    "\n",
    "First, let's import all other necessary libraries.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UiAE4g8aCP53"
   },
   "source": [
    "We set the hyperparameters as following:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 419,
     "status": "ok",
     "timestamp": 1603388382671,
     "user": {
      "displayName": "Christine Yu",
      "photoUrl": "",
      "userId": "17254532280477988261"
     },
     "user_tz": 420
    },
    "id": "kVQCpNXYCP53",
    "outputId": "f7d019c8-8afd-42a3-cf44-c9ef283faea5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[gpu(0)]\n"
     ]
    }
   ],
   "source": [
    "classes = 2\n",
    "\n",
    "epochs = 15\n",
    "lr = 0.001\n",
    "per_device_batch_size = 16\n",
    "momentum = 0.9\n",
    "wd = 0.0001\n",
    "\n",
    "lr_factor = 0.75\n",
    "lr_steps = [10, 20, 30, np.inf]\n",
    "\n",
    "num_gpus = 1\n",
    "num_workers = 8\n",
    "ctx = [mx.gpu(i) for i in range(num_gpus)] if num_gpus > 0 else [mx.cpu()]\n",
    "batch_size = per_device_batch_size * max(num_gpus, 1)\n",
    "print(ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "THLMmIhfCP56"
   },
   "source": [
    "Things to keep in mind:\n",
    "\n",
    "1. ``epochs = 5`` is just for this tutorial with the tiny dataset. please change it to a larger number in your experiments, for instance 40.\n",
    "2. ``per_device_batch_size`` is also set to a small number. In your experiments you can try larger number like 64.\n",
    "3. remember to tune ``num_gpus`` and ``num_workers`` according to your machine.\n",
    "4. A pre-trained model is already in a pretty good status. So we can start with a small ``lr``.\n",
    "\n",
    "## Data Augmentation\n",
    "\n",
    "In transfer learning, data augmentation can also help.\n",
    "We use the following augmentation in training:\n",
    "\n",
    "2. Randomly crop the image and resize it to 224x224\n",
    "3. Randomly flip the image horizontally\n",
    "4. Randomly jitter color and add noise\n",
    "5. Transpose the data from height*width*num_channels to num_channels*height*width, and map values from [0, 255] to [0, 1]\n",
    "6. Normalize with the mean and standard deviation from the ImageNet dataset.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 315,
     "status": "ok",
     "timestamp": 1603387567545,
     "user": {
      "displayName": "Christine Yu",
      "photoUrl": "",
      "userId": "17254532280477988261"
     },
     "user_tz": 420
    },
    "id": "CYgiHxUECP56"
   },
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize(600, keep_ratio=True),\n",
    "    transforms.CenterCrop(512),\n",
    "\n",
    "    transforms.RandomFlipLeftRight(), # Randomly flip the image horizontally\n",
    "    transforms.RandomFlipTopBottom(),\n",
    "    transforms.RandomLighting(0.1), # Add AlexNet-style PCA-based noise to an image\n",
    "    transforms.RandomContrast(0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(600, keep_ratio=True),\n",
    "    transforms.CenterCrop(512),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_OKZ2hq1CP59"
   },
   "source": [
    "With the data augmentation functions, we can define our data loaders:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 505,
     "status": "ok",
     "timestamp": 1603387569163,
     "user": {
      "displayName": "Christine Yu",
      "photoUrl": "",
      "userId": "17254532280477988261"
     },
     "user_tz": 420
    },
    "id": "226lVHP2CP5-",
    "outputId": "2f99ecc8-093e-4daf-ed99-db2fc1abfb9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n"
     ]
    }
   ],
   "source": [
    "data_path = f'{processed_path}/fluo_data/middle'\n",
    "train_path = os.path.join(data_path, 'train')\n",
    "val_path = os.path.join(data_path, 'val')\n",
    "test_path = os.path.join(data_path, 'test')\n",
    "\n",
    "train_data = gluon.data.DataLoader(\n",
    "    gluon.data.vision.ImageFolderDataset(train_path).transform_first(transform_train),\n",
    "    batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "\n",
    "val_data = gluon.data.DataLoader(\n",
    "    gluon.data.vision.ImageFolderDataset(val_path).transform_first(transform_train),\n",
    "    batch_size=batch_size, shuffle=True, num_workers = num_workers)\n",
    "\n",
    "test_data = gluon.data.DataLoader(\n",
    "    gluon.data.vision.ImageFolderDataset(test_path).transform_first(transform_test),\n",
    "    batch_size=batch_size, shuffle=False, num_workers = num_workers)\n",
    "\n",
    "print(len(train_data) + len(val_data) + len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_IkfDxPxCP6B"
   },
   "source": [
    "Note that only ``train_data`` uses ``transform_train``, while\n",
    "``val_data`` and ``test_data`` use ``transform_test`` to produce deterministic\n",
    "results for evaluation.\n",
    "\n",
    "## Model and Trainer\n",
    "\n",
    "We use a pre-trained ``ResNet50_v2`` model, which has balanced accuracy and\n",
    "computation cost.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 5934,
     "status": "ok",
     "timestamp": 1603387576828,
     "user": {
      "displayName": "Christine Yu",
      "photoUrl": "",
      "userId": "17254532280477988261"
     },
     "user_tz": 420
    },
    "id": "J8KZlje8CP6B"
   },
   "outputs": [],
   "source": [
    "model_name = 'ResNet50_v2'\n",
    "finetune_net = get_model(model_name, pretrained=True)\n",
    "with finetune_net.name_scope():\n",
    "    finetune_net.output = nn.Dense(classes)\n",
    "finetune_net.output.initialize(init.Xavier(), ctx = ctx)\n",
    "finetune_net.collect_params().reset_ctx(ctx)\n",
    "finetune_net.hybridize()\n",
    "\n",
    "trainer = gluon.Trainer(finetune_net.collect_params(), 'sgd', {\n",
    "                        'learning_rate': lr, 'momentum': momentum, 'wd': wd})\n",
    "metric = mx.metric.Accuracy()\n",
    "L = gluon.loss.SoftmaxCrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zjIqPfnNCP6E"
   },
   "source": [
    "Here's an illustration of the pre-trained model\n",
    "and our newly defined model:\n",
    "\n",
    "|image-model|\n",
    "\n",
    "Specifically, we define the new model by::\n",
    "\n",
    "1. load the pre-trained model\n",
    "2. re-define the output layer for the new task\n",
    "3. train the network\n",
    "\n",
    "This is called \"fine-tuning\", i.e. we have a model trained on another task,\n",
    "and we would like to tune it for the dataset we have in hand.\n",
    "\n",
    "We define a evaluation function for validation and testing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 314,
     "status": "ok",
     "timestamp": 1603387577634,
     "user": {
      "displayName": "Christine Yu",
      "photoUrl": "",
      "userId": "17254532280477988261"
     },
     "user_tz": 420
    },
    "id": "fzIMoYwlCP6E"
   },
   "outputs": [],
   "source": [
    "def test(net, val_data, ctx):\n",
    "    metric = mx.metric.Accuracy()\n",
    "    for i, batch in enumerate(val_data):\n",
    "        data = gluon.utils.split_and_load(batch[0], ctx_list=ctx, batch_axis=0, even_split=False)\n",
    "        label = gluon.utils.split_and_load(batch[1], ctx_list=ctx, batch_axis=0, even_split=False)\n",
    "        outputs = [net(X) for X in data]\n",
    "        metric.update(label, outputs)\n",
    "\n",
    "    return metric.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZJG2Rg_NCP6G"
   },
   "source": [
    "## Training Loop\n",
    "\n",
    "Following is the main training loop. It is the same as the loop in\n",
    "`CIFAR10 <dive_deep_cifar10.html>`__\n",
    "and ImageNet.\n",
    "\n",
    "<div class=\"alert alert-info\"><h4>Note</h4><p>Once again, in order to go through the tutorial faster, we are training on a small\n",
    "    subset of the original ``MINC-2500`` dataset, and for only 5 epochs. By training on the\n",
    "    full dataset with 40 epochs, it is expected to get accuracy around 80% on test data.</p></div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "kwRaiiomCP6H",
    "outputId": "90aec84b-f3d3-4fcc-bc9f-9434216e30f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0] Train-acc: 0.992, loss: 0.028 | Val-acc: 0.941 | time: 37.2\n"
     ]
    }
   ],
   "source": [
    "lr_counter = 0\n",
    "num_batch = len(train_data)\n",
    "train_acc_lst = []\n",
    "train_loss_lst = []\n",
    "val_acc_lst = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    if epoch == lr_steps[lr_counter]:\n",
    "        trainer.set_learning_rate(trainer.learning_rate*lr_factor)\n",
    "        lr_counter += 1\n",
    "\n",
    "    tic = time.time()\n",
    "    train_loss = 0\n",
    "    metric.reset()\n",
    "\n",
    "    for i, batch in enumerate(train_data):\n",
    "        data = gluon.utils.split_and_load(batch[0], ctx_list=ctx, batch_axis=0, even_split=False)\n",
    "        label = gluon.utils.split_and_load(batch[1], ctx_list=ctx, batch_axis=0, even_split=False)\n",
    "        with ag.record():\n",
    "            outputs = [finetune_net(X) for X in data]\n",
    "            loss = [L(yhat, y) for yhat, y in zip(outputs, label)]\n",
    "        for l in loss:\n",
    "            l.backward()\n",
    "\n",
    "        trainer.step(batch_size)\n",
    "        train_loss += sum([l.mean().asscalar() for l in loss]) / len(loss)\n",
    "\n",
    "        metric.update(label, outputs)\n",
    "\n",
    "    _, train_acc = metric.get()\n",
    "    train_loss /= num_batch\n",
    "\n",
    "    _, val_acc = test(finetune_net, val_data, ctx)\n",
    "\n",
    "    train_acc_lst.append(train_acc)\n",
    "    train_loss_lst.append(train_loss)\n",
    "    val_acc_lst.append(val_acc)\n",
    "    print('[Epoch %d] Train-acc: %.3f, loss: %.3f | Val-acc: %.3f | time: %.1f' %\n",
    "             (epoch, train_acc, train_loss, val_acc, time.time() - tic))\n",
    "\n",
    "_, test_acc = test(finetune_net, test_data, ctx)\n",
    "print('[Finished] Test-acc: %.3f' % (test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fiALUBnnZARh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kX-Dp9S5CP6J"
   },
   "source": [
    "## Next\n",
    "\n",
    "Now that you have learned to muster the power of transfer\n",
    "learning, to learn more about training a model on\n",
    "ImageNet, please read `this tutorial <dive_deep_imagenet.html>`__.\n",
    "\n",
    "The idea of transfer learning is the basis of\n",
    "`object detection <../examples_detection/index.html>`_ and\n",
    "`semantic segmentation <../examples_segmentation/index.html>`_,\n",
    "the next two chapters of our tutorial.\n",
    "\n",
    ".. |image-minc| image:: https://raw.githubusercontent.com/dmlc/web-data/master/gluoncv/datasets/MINC-2500.png\n",
    ".. |image-model| image:: https://zh.gluon.ai/_images/fine-tuning.svg\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "classify_fluo_pretrained.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
