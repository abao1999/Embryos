{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify Fluorescence Images as Polarized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook implements a basic CNN to classify fluorescent images of embryos as having or lacking polarized caps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mxnet in /home/abao/anaconda3/lib/python3.7/site-packages (1.6.0)\r\n",
      "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /home/abao/anaconda3/lib/python3.7/site-packages (from mxnet) (1.17.2)\r\n",
      "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /home/abao/anaconda3/lib/python3.7/site-packages (from mxnet) (0.8.4)\r\n",
      "Requirement already satisfied: requests<3,>=2.20.0 in /home/abao/anaconda3/lib/python3.7/site-packages (from mxnet) (2.22.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/abao/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.20.0->mxnet) (2019.9.11)\r\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/abao/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.20.0->mxnet) (2.8)\r\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/abao/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.20.0->mxnet) (1.24.2)\r\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/abao/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install mxnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import h5py\n",
    "import mxnet as mx\n",
    "from mxnet import gluon\n",
    "from mxnet.gluon import nn\n",
    "from mxnet import autograd as ag\n",
    "import utils\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Fixing the random seed\n",
    "mx.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet.ndarray as F\n",
    "\n",
    "class Net(gluon.Block):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Net, self).__init__(**kwargs)\n",
    "        with self.name_scope():\n",
    "            # layers created in name_scope will inherit name space\n",
    "            # from parent layer.\n",
    "            self.conv1 = nn.Conv2D(20, kernel_size=(5,5))\n",
    "            self.pool1 = nn.MaxPool2D(pool_size=(2,2), strides = (2,2))\n",
    "            self.conv2 = nn.Conv2D(50, kernel_size=(5,5))\n",
    "            self.pool2 = nn.MaxPool2D(pool_size=(2,2), strides = (2,2))\n",
    "            self.fc1 = nn.Dense(500)\n",
    "            self.fc2 = nn.Dense(2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.tanh(self.conv1(x)))\n",
    "        x = self.pool2(F.tanh(self.conv2(x)))\n",
    "        # 0 means copy over size from corresponding dimension.\n",
    "        # -1 means infer size from the rest of dimensions.\n",
    "        x = x.reshape((0, -1))\n",
    "        x = F.tanh(self.fc1(x))\n",
    "        x = F.tanh(self.fc2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the data\n",
    "fluo_data_path = \"../data/video_fluo_data\"\n",
    "embryo_idx = 46\n",
    "fluo = h5py.File(os.path.join(fluo_data_path,'embryo_'+str(embryo_idx)+'.mat'))\n",
    "arrays = {}\n",
    "for k, v in fluo.items():\n",
    "    arrays[k] = np.array(v)\n",
    "\n",
    "fluo_video = arrays['data']\n",
    "pol_state = arrays['anno']\n",
    "\n",
    "# a bit of data processing... get middle z slice\n",
    "fluo_video = np.array([utils.get_middle_z(fluo_video)])\n",
    "fluo_video = np.moveaxis(fluo_video, -1, 0)\n",
    "\n",
    "# # train-test split\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# # split 0.2 for test set\n",
    "# X_train, X_test, y_train, y_test = train_test_split(fluo_video, pol_state[0], test_size=0.2, random_state=42)\n",
    "# # split 0.2 for val set\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "# # keep 0.6 for train set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # define the batch size for data loading\n",
    "# batch_size = 30\n",
    "\n",
    "# # data loaders?\n",
    "# # iterator vs dataloader: https://mxnet.apache.org/versions/1.7/api/python/docs/tutorials/packages/gluon/data/datasets.html#Appendix:-Upgrading-from-Module-DataIter-to-Gluon-DataLoader\n",
    "# # dataloader: https://mxnet.apache.org/versions/1.7/api/python/docs/tutorials/packages/gluon/data/datasets.html\n",
    "# # data iterator: https://mxnet.apache.org/versions/1.1.0/tutorials/basic/data.html\n",
    "# train_data = mx.io.NDArrayIter(X_train, y_train, batch_size=batch_size, shuffle=True)\n",
    "# test_data = mx.io.NDArrayIter(X_test, y_test, batch_size=batch_size)\n",
    "# val_data = mx.io.NDArrayIter(X_val, y_val, batch_size=batch_size)\n",
    "# # # Convert to dataloader:\n",
    "# # data_iter_loader = DataIterLoader(data_iter)\n",
    "# # for X_batch, y_batch in data_iter_loader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the batch size for data loading\n",
    "batch_size = 30\n",
    "\n",
    "train_data = mx.io.NDArrayIter(fluo_video, pol_state[0], batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer, Metrics, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the context on GPU is available otherwise CPU\n",
    "ctx = [mx.gpu() if mx.test_utils.list_gpus() else mx.cpu()]\n",
    "net.initialize(mx.init.Xavier(magnitude=2.24), ctx=ctx)\n",
    "\n",
    "# For training\n",
    "# Use Accuracy as the evaluation metric.\n",
    "metric = mx.metric.Accuracy()\n",
    "softmax_cross_entropy_loss = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "\n",
    "# For validation/test\n",
    "# define an evaluation function for validation and testing\n",
    "def test(net, test_data, ctx):\n",
    "    metric = mx.metric.Accuracy()\n",
    "    for i, batch in enumerate(test_data):\n",
    "        data = gluon.utils.split_and_load(batch[0], ctx_list=ctx, batch_axis=0, even_split=False)\n",
    "        label = gluon.utils.split_and_load(batch[1], ctx_list=ctx, batch_axis=0, even_split=False)\n",
    "        outputs = [net(X) for X in data]\n",
    "        metric.update(label, outputs)\n",
    "    return metric.get()\n",
    "\n",
    "# learning rate\n",
    "lr = 0.001\n",
    "# lr_factor = 0.75 # Learning rate decay factor\n",
    "# lr_steps = [10, 20, 30, np.inf] # Epochs where learning rate decays\n",
    "wd = 0.0001\n",
    "momentum = 0.0\n",
    "optimizer = 'sgd' # 'nag': Nesterov accelerated gradient descent\n",
    "optimizer_params = {'learning_rate': lr, 'wd': wd, 'momentum': momentum} # Set parameters\n",
    "trainer = gluon.Trainer(net.collect_params(), optimizer, optimizer_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "<NDArray 30 @cpu(0)>] [\n",
      "[[ 0.14373255  0.36559972]\n",
      " [-0.27026007  0.35968503]\n",
      " [ 0.02855117  0.4424781 ]\n",
      " [-0.21087226  0.267378  ]\n",
      " [ 0.12967221  0.37347943]\n",
      " [-0.21080026  0.5813768 ]\n",
      " [-0.01696655  0.36416656]\n",
      " [ 0.32669455  0.04036618]\n",
      " [-0.10103721  0.46833882]\n",
      " [ 0.17513482  0.60633945]\n",
      " [ 0.01648585  0.29663554]\n",
      " [ 0.20187     0.4214257 ]\n",
      " [-0.0731499   0.33264264]\n",
      " [ 0.32309768 -0.08252288]\n",
      " [ 0.16820839  0.18376893]\n",
      " [-0.10447828  0.25685436]\n",
      " [-0.07699339  0.49889588]\n",
      " [-0.04840959  0.52380294]\n",
      " [ 0.25001052  0.26115426]\n",
      " [ 0.05989517  0.53913635]\n",
      " [-0.07991438  0.09435862]\n",
      " [ 0.14373255  0.36559972]\n",
      " [-0.27026007  0.35968503]\n",
      " [ 0.02855117  0.4424781 ]\n",
      " [-0.21087226  0.267378  ]\n",
      " [ 0.12967221  0.37347943]\n",
      " [-0.21080026  0.5813768 ]\n",
      " [-0.01696655  0.36416656]\n",
      " [ 0.32669455  0.04036618]\n",
      " [-0.10103721  0.46833882]]\n",
      "<NDArray 30x2 @cpu(0)>]\n",
      "training acc at epoch 0: accuracy=0.233333\n",
      "[\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0.]\n",
      "<NDArray 30 @cpu(0)>] [\n",
      "[[ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]]\n",
      "<NDArray 30x2 @cpu(0)>]\n",
      "training acc at epoch 1: accuracy=0.866667\n",
      "[\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "<NDArray 30 @cpu(0)>] [\n",
      "[[ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]]\n",
      "<NDArray 30x2 @cpu(0)>]\n",
      "training acc at epoch 2: accuracy=0.900000\n",
      "[\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "<NDArray 30 @cpu(0)>] [\n",
      "[[ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]]\n",
      "<NDArray 30x2 @cpu(0)>]\n",
      "training acc at epoch 3: accuracy=0.866667\n",
      "[\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0.]\n",
      "<NDArray 30 @cpu(0)>] [\n",
      "[[ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]]\n",
      "<NDArray 30x2 @cpu(0)>]\n",
      "training acc at epoch 4: accuracy=0.866667\n",
      "[\n",
      "[1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0.]\n",
      "<NDArray 30 @cpu(0)>] [\n",
      "[[ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]]\n",
      "<NDArray 30x2 @cpu(0)>]\n",
      "training acc at epoch 5: accuracy=0.833333\n",
      "[\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 1.]\n",
      "<NDArray 30 @cpu(0)>] "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-1ab6ecba593e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m                     \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0;31m# Updates internal evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36m__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;34m\"\"\"Returns a string representation of the array.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0mshape_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'x'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'%d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m         return '\\n%s\\n<%s %s @%s>' % (str(self.asnumpy()),\n\u001b[0m\u001b[1;32m    247\u001b[0m                                       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m                                       shape_info, self.context)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36masnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2533\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2534\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2535\u001b[0;31m             ctypes.c_size_t(data.size)))\n\u001b[0m\u001b[1;32m   2536\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "# lr_lst = [0.001, 0.005, 0.01, 0.05, 0.1]\n",
    "# low learning rate, high momentum\n",
    "lr_lst = [0.02]\n",
    "\n",
    "train_acc_over_hyperparam_tensor = []\n",
    "# val_acc_over_hyperparam_tensor = []\n",
    "\n",
    "for lr_val in lr_lst:\n",
    "    # set learning rate\n",
    "    trainer.set_learning_rate(lr_val)\n",
    "    \n",
    "    # store results\n",
    "    train_acc_lst = np.zeros(epochs)\n",
    "#     val_acc_lst = np.zeros(epochs)\n",
    "\n",
    "    for i in range(epochs):\n",
    "        # Reset the train data iterator.\n",
    "        train_data.reset()\n",
    "        # Loop over the train data iterator.\n",
    "        for batch in train_data:\n",
    "            # Splits train data into multiple slices along batch_axis\n",
    "            # and copy each slice into a context.\n",
    "            data = gluon.utils.split_and_load(batch.data[0], ctx_list=ctx, batch_axis=0)\n",
    "            # Splits train labels into multiple slices along batch_axis\n",
    "            # and copy each slice into a context.\n",
    "            label = gluon.utils.split_and_load(batch.label[0], ctx_list=ctx, batch_axis=0)\n",
    "            outputs = []\n",
    "            # Inside training scope\n",
    "            with ag.record():\n",
    "                for x, y in zip(data, label):\n",
    "                    z = net(x)\n",
    "                    # Computes softmax cross entropy loss.\n",
    "                    loss = softmax_cross_entropy_loss(z, y)\n",
    "                    # Backpropogate the error for one iteration.\n",
    "                    loss.backward()\n",
    "                    outputs.append(z)\n",
    "\n",
    "            print(label, outputs)\n",
    "            # Updates internal evaluation\n",
    "            metric.update(label, outputs)\n",
    "            # Make one step of parameter update. Trainer needs to know the\n",
    "            # batch size of data to normalize the gradient by 1/batch_size.\n",
    "            trainer.step(batch.data[0].shape[0])\n",
    "\n",
    "        # Gets the training evaluation result.\n",
    "        name, train_acc = metric.get()\n",
    "        train_acc_lst[i] = train_acc\n",
    "\n",
    "    #     # Gets the validation evaluation result.\n",
    "    #     name, val_acc = test(net,val_data,ctx)\n",
    "    #     val_acc_lst[i] = val_acc\n",
    "\n",
    "        # Reset evaluation result to initial state.\n",
    "        metric.reset()\n",
    "        print('training acc at epoch %d: %s=%f'%(i, name, train_acc))\n",
    "    \n",
    "    train_acc_over_hyperparam_tensor.append(train_acc_lst)\n",
    "#     val_acc_over_hyperparam_tensor.append(val_acc_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0,epochs,1),train_acc_over_hyperparam_tensor[0],'r')\n",
    "plt.ylabel('Training Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.title('CNN Classify Fluo Polarization')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# plt.figure()\n",
    "# plt.plot(np.arange(0,epochs,1),val_acc_lst,'r')\n",
    "# plt.ylabel('Validation Accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.title('CNN Classify Fluo Polarization')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
