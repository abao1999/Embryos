{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify Fluorescence Images as Polarized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook implements a basic CNN to classify fluorescent images of embryos as having or lacking polarized caps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mxnet in /home/abao/anaconda3/lib/python3.7/site-packages (1.6.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /home/abao/anaconda3/lib/python3.7/site-packages (from mxnet) (1.17.2)\n",
      "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /home/abao/anaconda3/lib/python3.7/site-packages (from mxnet) (0.8.4)\n",
      "Requirement already satisfied: requests<3,>=2.20.0 in /home/abao/anaconda3/lib/python3.7/site-packages (from mxnet) (2.22.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/abao/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.20.0->mxnet) (2019.9.11)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/abao/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.20.0->mxnet) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/abao/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.20.0->mxnet) (1.24.2)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/abao/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install mxnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import h5py\n",
    "import mxnet as mx\n",
    "from mxnet import gluon\n",
    "from mxnet.gluon import nn\n",
    "from mxnet import autograd as ag\n",
    "import utils\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Fixing the random seed\n",
    "mx.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet.ndarray as F\n",
    "\n",
    "class Net(gluon.Block):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Net, self).__init__(**kwargs)\n",
    "        with self.name_scope():\n",
    "            # layers created in name_scope will inherit name space\n",
    "            # from parent layer.\n",
    "            self.conv1 = nn.Conv2D(20, kernel_size=(5,5))\n",
    "            self.pool1 = nn.MaxPool2D(pool_size=(2,2), strides = (2,2))\n",
    "            self.conv2 = nn.Conv2D(50, kernel_size=(5,5))\n",
    "            self.pool2 = nn.MaxPool2D(pool_size=(2,2), strides = (2,2))\n",
    "            self.fc1 = nn.Dense(500)\n",
    "            self.fc2 = nn.Dense(10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.tanh(self.conv1(x)))\n",
    "        x = self.pool2(F.tanh(self.conv2(x)))\n",
    "        # 0 means copy over size from corresponding dimension.\n",
    "        # -1 means infer size from the rest of dimensions.\n",
    "        x = x.reshape((0, -1))\n",
    "        x = F.tanh(self.fc1(x))\n",
    "        x = F.tanh(self.fc2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the data\n",
    "fluo_data_path = \"../data/video_fluo_data\"\n",
    "embryo_idx = 46\n",
    "fluo = h5py.File(os.path.join(fluo_data_path,'embryo_'+str(embryo_idx)+'.mat'))\n",
    "arrays = {}\n",
    "for k, v in fluo.items():\n",
    "    arrays[k] = np.array(v)\n",
    "\n",
    "fluo_video = arrays['data']\n",
    "pol_state = arrays['anno']\n",
    "\n",
    "# a bit of data processing... get middle z slice\n",
    "fluo_video = np.array([utils.get_middle_z(fluo_video)])\n",
    "fluo_video = np.moveaxis(fluo_video, -1, 0)\n",
    "\n",
    "# # train-test split\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# # split 0.2 for test set\n",
    "# X_train, X_test, y_train, y_test = train_test_split(fluo_video, pol_state[0], test_size=0.2, random_state=42)\n",
    "# # split 0.2 for val set\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "# # keep 0.6 for train set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # define the batch size for data loading\n",
    "# batch_size = 30\n",
    "\n",
    "# # data loaders?\n",
    "# # iterator vs dataloader: https://mxnet.apache.org/versions/1.7/api/python/docs/tutorials/packages/gluon/data/datasets.html#Appendix:-Upgrading-from-Module-DataIter-to-Gluon-DataLoader\n",
    "# # dataloader: https://mxnet.apache.org/versions/1.7/api/python/docs/tutorials/packages/gluon/data/datasets.html\n",
    "# # data iterator: https://mxnet.apache.org/versions/1.1.0/tutorials/basic/data.html\n",
    "# train_data = mx.io.NDArrayIter(X_train, y_train, batch_size=batch_size, shuffle=True)\n",
    "# test_data = mx.io.NDArrayIter(X_test, y_test, batch_size=batch_size)\n",
    "# val_data = mx.io.NDArrayIter(X_val, y_val, batch_size=batch_size)\n",
    "# # # Convert to dataloader:\n",
    "# # data_iter_loader = DataIterLoader(data_iter)\n",
    "# # for X_batch, y_batch in data_iter_loader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the batch size for data loading\n",
    "batch_size = 30\n",
    "\n",
    "train_data = mx.io.NDArrayIter(fluo_video, pol_state[0], batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer, Metrics, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the context on GPU is available otherwise CPU\n",
    "ctx = [mx.gpu() if mx.test_utils.list_gpus() else mx.cpu()]\n",
    "net.initialize(mx.init.Xavier(magnitude=2.24), ctx=ctx)\n",
    "\n",
    "# For training\n",
    "# Use Accuracy as the evaluation metric.\n",
    "metric = mx.metric.Accuracy()\n",
    "softmax_cross_entropy_loss = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "\n",
    "# For validation/test\n",
    "# define an evaluation function for validation and testing\n",
    "def test(net, test_data, ctx):\n",
    "    metric = mx.metric.Accuracy()\n",
    "    for i, batch in enumerate(test_data):\n",
    "        data = gluon.utils.split_and_load(batch[0], ctx_list=ctx, batch_axis=0, even_split=False)\n",
    "        label = gluon.utils.split_and_load(batch[1], ctx_list=ctx, batch_axis=0, even_split=False)\n",
    "        outputs = [net(X) for X in data]\n",
    "        metric.update(label, outputs)\n",
    "    return metric.get()\n",
    "\n",
    "# learning rate\n",
    "lr = 0.001\n",
    "# lr_factor = 0.75 # Learning rate decay factor\n",
    "# lr_steps = [10, 20, 30, np.inf] # Epochs where learning rate decays\n",
    "wd = 0.0001\n",
    "momentum = 0.0\n",
    "optimizer = 'sgd' # 'nag': Nesterov accelerated gradient descent\n",
    "optimizer_params = {'learning_rate': lr, 'wd': wd, 'momentum': momentum} # Set parameters\n",
    "trainer = gluon.Trainer(net.collect_params(), optimizer, optimizer_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "[[ 0.4027144  -0.3358116   0.19056518 -0.29455036 -0.21242803 -0.2171781\n",
      "  -0.52781236 -0.04942893 -0.3094047  -0.05660508]\n",
      " [ 0.53011316 -0.63680214 -0.39182144 -0.09116478 -0.7164045  -0.08754303\n",
      "  -0.4396961  -0.1586413  -0.14806099 -0.26395816]\n",
      " [ 0.06284894 -0.44819075 -0.07256185 -0.4588292  -0.5458534  -0.37209377\n",
      "  -0.5403874  -0.3249575   0.21480331 -0.1048461 ]\n",
      " [ 0.20850633 -0.20633858  0.06297897 -0.2435733  -0.25975066 -0.3067129\n",
      "  -0.52038765 -0.16739579 -0.28902507 -0.60237366]\n",
      " [ 0.57742804 -0.51305705  0.168346   -0.10987832 -0.56131077 -0.21967039\n",
      "  -0.4721991  -0.3952559  -0.05867163 -0.5775438 ]\n",
      " [ 0.1710422  -0.5260894   0.20846021  0.0779351  -0.34675062 -0.11367808\n",
      "  -0.11450924 -0.28892437 -0.4174337  -0.31881067]\n",
      " [ 0.08692427 -0.70103496 -0.00814382  0.01924912 -0.3508587  -0.20235853\n",
      "  -0.52986264 -0.342671    0.12113825 -0.49495983]\n",
      " [ 0.5137457  -0.57089025 -0.31584543 -0.3257418  -0.5974002   0.02869307\n",
      "  -0.46210766 -0.4707121   0.3337852  -0.3933422 ]\n",
      " [ 0.5305939  -0.56588316  0.19120213 -0.39105338 -0.48963338 -0.00409069\n",
      "  -0.41919118 -0.4402698   0.14093614 -0.26101008]\n",
      " [ 0.49971583 -0.22603928  0.4998987  -0.04003473 -0.5169433  -0.05752806\n",
      "  -0.5306157  -0.2096933   0.1748597  -0.3696381 ]\n",
      " [ 0.09517892 -0.55049944  0.25118893 -0.46981528 -0.35189575  0.05681424\n",
      "  -0.15879652 -0.40412727  0.36792272 -0.35891035]\n",
      " [ 0.47011903 -0.51133716  0.13563885 -0.26322395 -0.15440482 -0.25516465\n",
      "  -0.34898272 -0.15697792 -0.16390179 -0.02590903]\n",
      " [ 0.44717678 -0.16598164  0.08071621 -0.41521433 -0.50878245 -0.0154652\n",
      "  -0.29723874 -0.29818624  0.13480999 -0.21987794]\n",
      " [ 0.56007755 -0.4824677  -0.01247183 -0.4807154  -0.5418314  -0.21124342\n",
      "  -0.5229248  -0.4159687   0.13440874 -0.3848072 ]\n",
      " [ 0.5430037  -0.485687    0.38154334 -0.124129   -0.1825309   0.07009799\n",
      "  -0.40131935 -0.4948219   0.5212086  -0.34020296]\n",
      " [ 0.21233293 -0.42574146  0.20513707 -0.13505553 -0.3461376  -0.33274737\n",
      "  -0.39149916 -0.6594957  -0.04827532 -0.23656753]\n",
      " [ 0.5359793  -0.38889062  0.06834719 -0.17554371 -0.40788066 -0.0641975\n",
      "  -0.4084901  -0.28354636 -0.11595382 -0.3447101 ]\n",
      " [ 0.49167755 -0.50736827 -0.3958483   0.18504016 -0.26061693 -0.39133117\n",
      "  -0.48256636 -0.4450212   0.26709217 -0.3524927 ]\n",
      " [ 0.2392956  -0.54133     0.13317916 -0.4008744  -0.28554046 -0.02113111\n",
      "  -0.26694226 -0.63860905  0.03739877 -0.1695787 ]\n",
      " [-0.04951574 -0.3747151  -0.23353541  0.02573767  0.0483783   0.00946505\n",
      "  -0.47088337 -0.37544388 -0.1824808  -0.39912817]\n",
      " [ 0.2025211  -0.4749757   0.26272407 -0.05849489 -0.33750284  0.03059874\n",
      "  -0.32848084 -0.23050398  0.2302559  -0.16113131]\n",
      " [ 0.4027144  -0.3358116   0.19056518 -0.29455036 -0.21242803 -0.2171781\n",
      "  -0.52781236 -0.04942893 -0.3094047  -0.05660508]\n",
      " [ 0.53011316 -0.63680214 -0.39182144 -0.09116478 -0.7164045  -0.08754303\n",
      "  -0.4396961  -0.1586413  -0.14806099 -0.26395816]\n",
      " [ 0.06284894 -0.44819075 -0.07256185 -0.4588292  -0.5458534  -0.37209377\n",
      "  -0.5403874  -0.3249575   0.21480331 -0.1048461 ]\n",
      " [ 0.20850633 -0.20633858  0.06297897 -0.2435733  -0.25975066 -0.3067129\n",
      "  -0.52038765 -0.16739579 -0.28902507 -0.60237366]\n",
      " [ 0.57742804 -0.51305705  0.168346   -0.10987832 -0.56131077 -0.21967039\n",
      "  -0.4721991  -0.3952559  -0.05867163 -0.5775438 ]\n",
      " [ 0.1710422  -0.5260894   0.20846021  0.0779351  -0.34675062 -0.11367808\n",
      "  -0.11450924 -0.28892437 -0.4174337  -0.31881067]\n",
      " [ 0.08692427 -0.70103496 -0.00814382  0.01924912 -0.3508587  -0.20235853\n",
      "  -0.52986264 -0.342671    0.12113825 -0.49495983]\n",
      " [ 0.5137457  -0.57089025 -0.31584543 -0.3257418  -0.5974002   0.02869307\n",
      "  -0.46210766 -0.4707121   0.3337852  -0.3933422 ]\n",
      " [ 0.5305939  -0.56588316  0.19120213 -0.39105338 -0.48963338 -0.00409069\n",
      "  -0.41919118 -0.4402698   0.14093614 -0.26101008]]\n",
      "<NDArray 30x10 @cpu(0)>]\n",
      "training acc at epoch 0: accuracy=0.533333\n",
      "[\n",
      "[[ 1.          0.9973967  -0.9990628  -0.99845195 -0.9978304  -0.2433196\n",
      "  -0.9857663  -0.93090004 -0.9780734  -0.9977306 ]\n",
      " [ 1.          0.9972564  -0.9988869  -0.9984175  -0.997893   -0.1397289\n",
      "  -0.98577    -0.9204484  -0.97507864 -0.9977998 ]\n",
      " [ 1.          0.9974684  -0.9990455  -0.99846834 -0.99802196 -0.24890047\n",
      "  -0.9834173  -0.9275986  -0.9770967  -0.9979349 ]\n",
      " [ 1.          0.99766636 -0.9991205  -0.99861133 -0.99826163 -0.2646154\n",
      "  -0.9846521  -0.9268991  -0.9777807  -0.99811393]\n",
      " [ 1.          0.9977189  -0.99913204 -0.99848527 -0.99809283 -0.25343955\n",
      "  -0.9852301  -0.9265887  -0.9783198  -0.9979314 ]\n",
      " [ 1.          0.9976217  -0.99901015 -0.9984287  -0.9979957  -0.19870406\n",
      "  -0.98497087 -0.913964   -0.9772328  -0.9979298 ]\n",
      " [ 1.          0.9967544  -0.9989817  -0.9983806  -0.9977082  -0.17676568\n",
      "  -0.98549294 -0.92935634 -0.9763118  -0.9977019 ]\n",
      " [ 1.          0.9967498  -0.9990459  -0.99831164 -0.99758863 -0.12599793\n",
      "  -0.9867208  -0.9305322  -0.9747167  -0.9977526 ]\n",
      " [ 1.          0.9977183  -0.99904114 -0.99851173 -0.9980119  -0.27991408\n",
      "  -0.98457116 -0.92772174 -0.9789796  -0.9978284 ]\n",
      " [ 1.          0.99737847 -0.9989479  -0.99850714 -0.99813044 -0.1825344\n",
      "  -0.98470414 -0.91440254 -0.9765161  -0.9980236 ]\n",
      " [ 1.          0.9978026  -0.9989827  -0.99852204 -0.99796283 -0.22972904\n",
      "  -0.9860156  -0.92305243 -0.97874385 -0.99798167]\n",
      " [ 1.          0.99722123 -0.99916404 -0.9985124  -0.9980887  -0.25948277\n",
      "  -0.9845213  -0.93527114 -0.9762705  -0.99804574]\n",
      " [ 1.          0.9973896  -0.9991286  -0.99838376 -0.99798644 -0.21905053\n",
      "  -0.9861024  -0.9241964  -0.97802925 -0.99802154]\n",
      " [ 1.          0.9976406  -0.9989939  -0.99849105 -0.99797046 -0.23803496\n",
      "  -0.985432   -0.9220743  -0.97865474 -0.9977486 ]\n",
      " [ 1.          0.99932104 -0.9991692  -0.9990421  -0.9985559  -0.42885968\n",
      "  -0.9838247  -0.9453789  -0.9852403  -0.99847996]\n",
      " [ 1.          0.99763155 -0.99898773 -0.99845123 -0.9979481  -0.22403687\n",
      "  -0.98613775 -0.91859186 -0.9781538  -0.99778074]\n",
      " [ 1.          0.99912304 -0.99908626 -0.99892485 -0.9984553  -0.41449583\n",
      "  -0.98592293 -0.94043845 -0.98339486 -0.9982384 ]\n",
      " [ 1.          0.99758214 -0.9989884  -0.9983825  -0.9979609  -0.22215527\n",
      "  -0.98501354 -0.918672   -0.9781898  -0.9979747 ]\n",
      " [ 1.          0.99709666 -0.9990518  -0.9984846  -0.9978069  -0.29923606\n",
      "  -0.9849353  -0.9341832  -0.9792565  -0.99781936]\n",
      " [ 1.          0.999306   -0.9991708  -0.99906796 -0.9985896  -0.442627\n",
      "  -0.9845007  -0.94586855 -0.9842226  -0.99847037]\n",
      " [ 1.          0.9972354  -0.9989574  -0.998405   -0.99792    -0.23810183\n",
      "  -0.98603684 -0.9245127  -0.97825    -0.9979029 ]\n",
      " [ 1.          0.9973967  -0.9990628  -0.99845195 -0.9978304  -0.2433196\n",
      "  -0.9857663  -0.93090004 -0.9780734  -0.9977306 ]\n",
      " [ 1.          0.9972564  -0.9988869  -0.9984175  -0.997893   -0.1397289\n",
      "  -0.98577    -0.9204484  -0.97507864 -0.9977998 ]\n",
      " [ 1.          0.9974684  -0.9990455  -0.99846834 -0.99802196 -0.24890047\n",
      "  -0.9834173  -0.9275986  -0.9770967  -0.9979349 ]\n",
      " [ 1.          0.99766636 -0.9991205  -0.99861133 -0.99826163 -0.2646154\n",
      "  -0.9846521  -0.9268991  -0.9777807  -0.99811393]\n",
      " [ 1.          0.9977189  -0.99913204 -0.99848527 -0.99809283 -0.25343955\n",
      "  -0.9852301  -0.9265887  -0.9783198  -0.9979314 ]\n",
      " [ 1.          0.9976217  -0.99901015 -0.9984287  -0.9979957  -0.19870406\n",
      "  -0.98497087 -0.913964   -0.9772328  -0.9979298 ]\n",
      " [ 1.          0.9967544  -0.9989817  -0.9983806  -0.9977082  -0.17676568\n",
      "  -0.98549294 -0.92935634 -0.9763118  -0.9977019 ]\n",
      " [ 1.          0.9967498  -0.9990459  -0.99831164 -0.99758863 -0.12599793\n",
      "  -0.9867208  -0.9305322  -0.9747167  -0.9977526 ]\n",
      " [ 1.          0.9977183  -0.99904114 -0.99851173 -0.9980119  -0.27991408\n",
      "  -0.98457116 -0.92772174 -0.9789796  -0.9978284 ]]\n",
      "<NDArray 30x10 @cpu(0)>]\n",
      "training acc at epoch 1: accuracy=0.900000\n",
      "[\n",
      "[[ 1.          0.99694    -0.9992407  -0.9986403  -0.9983905  -0.9410888\n",
      "  -0.97965145 -0.9642764  -0.9856654  -0.9982665 ]\n",
      " [ 1.          0.996341   -0.99919456 -0.99864066 -0.99818254 -0.9414607\n",
      "  -0.97937965 -0.96637154 -0.9857253  -0.9983148 ]\n",
      " [ 1.          0.9969397  -0.9992322  -0.9987145  -0.9983341  -0.940526\n",
      "  -0.9803983  -0.96502775 -0.9858495  -0.9982184 ]\n",
      " [ 1.          0.9990144  -0.9994064  -0.9992835  -0.9986018  -0.9611919\n",
      "  -0.9805905  -0.9755171  -0.9895867  -0.9984222 ]\n",
      " [ 1.          0.9988654  -0.99936783 -0.9992053  -0.9985725  -0.9601903\n",
      "  -0.9812398  -0.9746688  -0.9891633  -0.99817693]\n",
      " [ 1.          0.99691796 -0.99920255 -0.99865186 -0.99831605 -0.9424856\n",
      "  -0.9795729  -0.9649836  -0.98674035 -0.9982927 ]\n",
      " [ 1.          0.9968589  -0.9991891  -0.99869084 -0.99823487 -0.9418854\n",
      "  -0.9804937  -0.96594954 -0.9863059  -0.9982394 ]\n",
      " [ 1.          0.9972371  -0.9992245  -0.9987452  -0.99823934 -0.94105583\n",
      "  -0.98116577 -0.9666055  -0.9862639  -0.9982698 ]\n",
      " [ 1.          0.9964296  -0.9992271  -0.99868524 -0.99827343 -0.9453172\n",
      "  -0.9787596  -0.9654492  -0.9859852  -0.99837345]\n",
      " [ 1.          0.99904436 -0.99942684 -0.99926513 -0.99866855 -0.96206266\n",
      "  -0.9796704  -0.9767105  -0.99007696 -0.99830943]\n",
      " [ 1.          0.9966741  -0.9991919  -0.99864364 -0.99821097 -0.9397432\n",
      "  -0.9809798  -0.9653206  -0.98617446 -0.99815893]\n",
      " [ 1.          0.99668306 -0.9992046  -0.99865764 -0.9981791  -0.9406984\n",
      "  -0.9803505  -0.9667953  -0.985814   -0.99827987]\n",
      " [ 1.          0.9967816  -0.999234   -0.9986705  -0.9983598  -0.9423227\n",
      "  -0.9790164  -0.96417296 -0.9864816  -0.99837285]\n",
      " [ 1.          0.9969413  -0.9992263  -0.99868715 -0.9982814  -0.94164824\n",
      "  -0.9806495  -0.9654669  -0.9854106  -0.99822146]\n",
      " [ 1.          0.9963979  -0.9991669  -0.9985681  -0.99813026 -0.941801\n",
      "  -0.97969687 -0.9666749  -0.9851737  -0.99822503]\n",
      " [ 1.          0.9966358  -0.9992787  -0.99867517 -0.9983993  -0.9421513\n",
      "  -0.9795242  -0.96456176 -0.98590344 -0.99837106]\n",
      " [ 1.          0.99645364 -0.9992943  -0.99871224 -0.99830544 -0.9429249\n",
      "  -0.97938484 -0.9650644  -0.9860105  -0.9984143 ]\n",
      " [ 1.          0.99711114 -0.99927557 -0.9987655  -0.99848425 -0.9442454\n",
      "  -0.97923917 -0.9643957  -0.9865569  -0.99834543]\n",
      " [ 1.          0.9963503  -0.99920034 -0.998564   -0.9981927  -0.94427395\n",
      "  -0.9792955  -0.96625715 -0.9860808  -0.99835867]\n",
      " [ 1.          0.996945   -0.99924535 -0.9987153  -0.9983331  -0.9390682\n",
      "  -0.98049706 -0.96439743 -0.9857504  -0.99819857]\n",
      " [ 1.          0.9970146  -0.9992076  -0.998681   -0.99827194 -0.9396256\n",
      "  -0.9802413  -0.9652033  -0.98595804 -0.99816465]\n",
      " [ 1.          0.99694    -0.9992407  -0.9986403  -0.9983905  -0.9410888\n",
      "  -0.97965145 -0.9642764  -0.9856654  -0.9982665 ]\n",
      " [ 1.          0.996341   -0.99919456 -0.99864066 -0.99818254 -0.9414607\n",
      "  -0.97937965 -0.96637154 -0.9857253  -0.9983148 ]\n",
      " [ 1.          0.9969397  -0.9992322  -0.9987145  -0.9983341  -0.940526\n",
      "  -0.9803983  -0.96502775 -0.9858495  -0.9982184 ]\n",
      " [ 1.          0.9990144  -0.9994064  -0.9992835  -0.9986018  -0.9611919\n",
      "  -0.9805905  -0.9755171  -0.9895867  -0.9984222 ]\n",
      " [ 1.          0.9988654  -0.99936783 -0.9992053  -0.9985725  -0.9601903\n",
      "  -0.9812398  -0.9746688  -0.9891633  -0.99817693]\n",
      " [ 1.          0.99691796 -0.99920255 -0.99865186 -0.99831605 -0.9424856\n",
      "  -0.9795729  -0.9649836  -0.98674035 -0.9982927 ]\n",
      " [ 1.          0.9968589  -0.9991891  -0.99869084 -0.99823487 -0.9418854\n",
      "  -0.9804937  -0.96594954 -0.9863059  -0.9982394 ]\n",
      " [ 1.          0.9972371  -0.9992245  -0.9987452  -0.99823934 -0.94105583\n",
      "  -0.98116577 -0.9666055  -0.9862639  -0.9982698 ]\n",
      " [ 1.          0.9964296  -0.9992271  -0.99868524 -0.99827343 -0.9453172\n",
      "  -0.9787596  -0.9654492  -0.9859852  -0.99837345]]\n",
      "<NDArray 30x10 @cpu(0)>]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training acc at epoch 2: accuracy=0.833333\n",
      "[\n",
      "[[ 1.          0.9966996  -0.99922305 -0.9987101  -0.99829805 -0.9489021\n",
      "  -0.9809279  -0.9681781  -0.9864141  -0.9982822 ]\n",
      " [ 1.          0.99638635 -0.99918604 -0.9986378  -0.9981081  -0.94912606\n",
      "  -0.98086816 -0.9702233  -0.98631096 -0.99834985]\n",
      " [ 1.          0.9961256  -0.99928296 -0.99870104 -0.9982417  -0.9511576\n",
      "  -0.9799998  -0.9685837  -0.9865723  -0.9984822 ]\n",
      " [ 1.          0.9967389  -0.9992389  -0.99871665 -0.99830323 -0.94721186\n",
      "  -0.98108596 -0.9675309  -0.9862244  -0.9982488 ]\n",
      " [ 1.          0.9967984  -0.9991913  -0.9986683  -0.99822575 -0.9479807\n",
      "  -0.98077    -0.9684332  -0.98649204 -0.99821854]\n",
      " [ 1.          0.9965881  -0.99917406 -0.99868196 -0.99818254 -0.95011777\n",
      "  -0.9810288  -0.9692138  -0.9869375  -0.9983109 ]\n",
      " [ 1.          0.99707574 -0.9992133  -0.99874806 -0.9981826  -0.9490553\n",
      "  -0.9818847  -0.96998745 -0.9867773  -0.9983274 ]\n",
      " [ 1.          0.9967001  -0.9992172  -0.9986784  -0.99823344 -0.94977057\n",
      "  -0.9811775  -0.9687812  -0.9858656  -0.9982869 ]\n",
      " [ 1.          0.9967173  -0.999226   -0.9986271  -0.9983428  -0.9491347\n",
      "  -0.9802342  -0.96777534 -0.98614776 -0.99831444]\n",
      " [ 1.          0.99652195 -0.99921584 -0.99866015 -0.99830276 -0.9504101\n",
      "  -0.9796259  -0.9676657  -0.9870743  -0.9984303 ]\n",
      " [ 1.          0.99636924 -0.9992707  -0.99867374 -0.99835855 -0.9501507\n",
      "  -0.98017126 -0.96805733 -0.98640054 -0.9984268 ]\n",
      " [ 1.          0.9963687  -0.99917775 -0.998627   -0.9981593  -0.9481321\n",
      "  -0.9814821  -0.96859396 -0.9867127  -0.9982244 ]\n",
      " [ 1.          0.99694    -0.99927026 -0.9987783  -0.9984551  -0.95182765\n",
      "  -0.9799717  -0.9676996  -0.9871531  -0.99839544]\n",
      " [ 1.          0.9960143  -0.9991455  -0.9985328  -0.99806845 -0.950262\n",
      "  -0.9800124  -0.96991205 -0.985601   -0.99829453]\n",
      " [ 1.          0.99596536 -0.99917936 -0.9985309  -0.99811506 -0.9524758\n",
      "  -0.97975737 -0.9698046  -0.9865875  -0.9984269 ]\n",
      " [ 1.          0.9990077  -0.9994111  -0.99929637 -0.99860924 -0.96602356\n",
      "  -0.981494   -0.97759557 -0.99000347 -0.99842525]\n",
      " [ 1.          0.99886733 -0.9993779  -0.99922764 -0.9985787  -0.96542984\n",
      "  -0.9820877  -0.976998   -0.98962957 -0.99819946]\n",
      " [ 1.          0.99903643 -0.9994321  -0.9992746  -0.99867505 -0.9670277\n",
      "  -0.9805904  -0.9787784  -0.9904589  -0.9983167 ]\n",
      " [ 1.          0.99669236 -0.9991806  -0.9986402  -0.9982566  -0.95049417\n",
      "  -0.9802125  -0.9685681  -0.98731536 -0.9983452 ]\n",
      " [ 1.          0.99592954 -0.99917287 -0.99861234 -0.9981145  -0.9502089\n",
      "  -0.97972465 -0.96972203 -0.9862552  -0.9983957 ]\n",
      " [ 1.          0.9960405  -0.9992102  -0.99866354 -0.99821204 -0.95345634\n",
      "  -0.9791233  -0.9689064  -0.9864851  -0.9984435 ]\n",
      " [ 1.          0.9966996  -0.99922305 -0.9987101  -0.99829805 -0.9489021\n",
      "  -0.9809279  -0.9681781  -0.9864141  -0.9982822 ]\n",
      " [ 1.          0.99638635 -0.99918604 -0.9986378  -0.9981081  -0.94912606\n",
      "  -0.98086816 -0.9702233  -0.98631096 -0.99834985]\n",
      " [ 1.          0.9961256  -0.99928296 -0.99870104 -0.9982417  -0.9511576\n",
      "  -0.9799998  -0.9685837  -0.9865723  -0.9984822 ]\n",
      " [ 1.          0.9967389  -0.9992389  -0.99871665 -0.99830323 -0.94721186\n",
      "  -0.98108596 -0.9675309  -0.9862244  -0.9982488 ]\n",
      " [ 1.          0.9967984  -0.9991913  -0.9986683  -0.99822575 -0.9479807\n",
      "  -0.98077    -0.9684332  -0.98649204 -0.99821854]\n",
      " [ 1.          0.9965881  -0.99917406 -0.99868196 -0.99818254 -0.95011777\n",
      "  -0.9810288  -0.9692138  -0.9869375  -0.9983109 ]\n",
      " [ 1.          0.99707574 -0.9992133  -0.99874806 -0.9981826  -0.9490553\n",
      "  -0.9818847  -0.96998745 -0.9867773  -0.9983274 ]\n",
      " [ 1.          0.9967001  -0.9992172  -0.9986784  -0.99823344 -0.94977057\n",
      "  -0.9811775  -0.9687812  -0.9858656  -0.9982869 ]\n",
      " [ 1.          0.9967173  -0.999226   -0.9986271  -0.9983428  -0.9491347\n",
      "  -0.9802342  -0.96777534 -0.98614776 -0.99831444]]\n",
      "<NDArray 30x10 @cpu(0)>]\n",
      "training acc at epoch 3: accuracy=0.900000\n",
      "[\n",
      "[[ 1.          0.99626094 -0.9992047  -0.9986431  -0.9981482  -0.95687246\n",
      "  -0.9814975  -0.9720651  -0.9863102  -0.9983862 ]\n",
      " [ 1.          0.99533147 -0.99915606 -0.9984732  -0.99800414 -0.9595327\n",
      "  -0.98001766 -0.9731844  -0.98710644 -0.99852425]\n",
      " [ 1.          0.995887   -0.9992588  -0.9986465  -0.9982849  -0.9571498\n",
      "  -0.98059976 -0.9715043  -0.98688775 -0.99851334]\n",
      " [ 1.          0.9961001  -0.99915594 -0.99864846 -0.9980949  -0.957306\n",
      "  -0.9813463  -0.97243077 -0.9875541  -0.9984166 ]\n",
      " [ 1.          0.99625975 -0.9992113  -0.99868184 -0.9982293  -0.95617926\n",
      "  -0.9812417  -0.9713162  -0.9869778  -0.99838066]\n",
      " [ 1.          0.9952455  -0.99914694 -0.9985574  -0.9980107  -0.95774436\n",
      "  -0.97985095 -0.9730277  -0.9867775  -0.9985047 ]\n",
      " [ 1.          0.9967472  -0.9991996  -0.99872696 -0.9980928  -0.9560085\n",
      "  -0.98238665 -0.97325224 -0.9872507  -0.9984161 ]\n",
      " [ 1.          0.9953909  -0.99918807 -0.9986142  -0.9981146  -0.9604236\n",
      "  -0.9792894  -0.97229487 -0.98698735 -0.9985409 ]\n",
      " [ 1.          0.99900305 -0.99943846 -0.99927866 -0.9986795  -0.97085214\n",
      "  -0.98133785 -0.98047775 -0.9907983  -0.99833316]\n",
      " [ 1.          0.9953942  -0.99912333 -0.9984771  -0.9979797  -0.95750153\n",
      "  -0.98013866 -0.9730041  -0.9860458  -0.998393  ]\n",
      " [ 1.          0.99555516 -0.99926496 -0.9986596  -0.99813485 -0.9583023\n",
      "  -0.98041254 -0.9721188  -0.98713326 -0.99857706]\n",
      " [ 1.          0.99585474 -0.99916327 -0.9985907  -0.9979991  -0.9565765\n",
      "  -0.9811523  -0.97360575 -0.9867935  -0.9984543 ]\n",
      " [ 1.          0.9966001  -0.99926496 -0.9987729  -0.9984025  -0.9583616\n",
      "  -0.98050416 -0.97087777 -0.9877506  -0.998477  ]\n",
      " [ 1.          0.99898    -0.99941564 -0.99930394 -0.99861777 -0.9697349\n",
      "  -0.98224825 -0.97929305 -0.99036074 -0.9984318 ]\n",
      " [ 1.          0.99635077 -0.99923104 -0.9986968  -0.9982451  -0.9543669\n",
      "  -0.98145956 -0.97065973 -0.9866675  -0.9983351 ]\n",
      " [ 1.          0.99883837 -0.99938756 -0.99924237 -0.99858445 -0.9693899\n",
      "  -0.9827969  -0.97886896 -0.9900016  -0.9982286 ]\n",
      " [ 1.          0.99603707 -0.9991939  -0.99862236 -0.99821055 -0.95752406\n",
      "  -0.97999036 -0.9711226  -0.98765665 -0.99852175]\n",
      " [ 1.          0.9963833  -0.99917114 -0.99862856 -0.99814373 -0.9553414\n",
      "  -0.9810677  -0.9716782  -0.98701197 -0.9983109 ]\n",
      " [ 1.          0.99583364 -0.9991592  -0.99858284 -0.9980688  -0.9555278\n",
      "  -0.981773   -0.97187096 -0.98723364 -0.9983266 ]\n",
      " [ 1.          0.9962879  -0.9992076  -0.998585   -0.9982607  -0.9562701\n",
      "  -0.98057073 -0.97122896 -0.9866286  -0.99840015]\n",
      " [ 1.          0.9962608  -0.9991543  -0.99860007 -0.9981609  -0.95752364\n",
      "  -0.9806105  -0.9720564  -0.9878655  -0.9984344 ]\n",
      " [ 1.          0.99626094 -0.9992047  -0.9986431  -0.9981482  -0.95687246\n",
      "  -0.9814975  -0.9720651  -0.9863102  -0.9983862 ]\n",
      " [ 1.          0.99533147 -0.99915606 -0.9984732  -0.99800414 -0.9595327\n",
      "  -0.98001766 -0.9731844  -0.98710644 -0.99852425]\n",
      " [ 1.          0.995887   -0.9992588  -0.9986465  -0.9982849  -0.9571498\n",
      "  -0.98059976 -0.9715043  -0.98688775 -0.99851334]\n",
      " [ 1.          0.9961001  -0.99915594 -0.99864846 -0.9980949  -0.957306\n",
      "  -0.9813463  -0.97243077 -0.9875541  -0.9984166 ]\n",
      " [ 1.          0.99625975 -0.9992113  -0.99868184 -0.9982293  -0.95617926\n",
      "  -0.9812417  -0.9713162  -0.9869778  -0.99838066]\n",
      " [ 1.          0.9952455  -0.99914694 -0.9985574  -0.9980107  -0.95774436\n",
      "  -0.97985095 -0.9730277  -0.9867775  -0.9985047 ]\n",
      " [ 1.          0.9967472  -0.9991996  -0.99872696 -0.9980928  -0.9560085\n",
      "  -0.98238665 -0.97325224 -0.9872507  -0.9984161 ]\n",
      " [ 1.          0.9953909  -0.99918807 -0.9986142  -0.9981146  -0.9604236\n",
      "  -0.9792894  -0.97229487 -0.98698735 -0.9985409 ]\n",
      " [ 1.          0.99900305 -0.99943846 -0.99927866 -0.9986795  -0.97085214\n",
      "  -0.98133785 -0.98047775 -0.9907983  -0.99833316]]\n",
      "<NDArray 30x10 @cpu(0)>]\n",
      "training acc at epoch 4: accuracy=0.866667\n",
      "[\n",
      "[[ 1.          0.9941977  -0.99911374 -0.99847585 -0.99787    -0.96403825\n",
      "  -0.9798294  -0.97614706 -0.987316   -0.9986311 ]\n",
      " [ 1.          0.9960107  -0.9992529  -0.9987364  -0.99831164 -0.96398574\n",
      "  -0.9808405  -0.97399104 -0.9883329  -0.998584  ]\n",
      " [ 1.          0.9956866  -0.9991444  -0.9985545  -0.99801654 -0.9616996\n",
      "  -0.9811671  -0.9748374  -0.98753047 -0.99843454]\n",
      " [ 1.          0.99894136 -0.99944776 -0.99927694 -0.9986813  -0.9739679\n",
      "  -0.98195136 -0.981943   -0.9911237  -0.9983652 ]\n",
      " [ 1.          0.9987804  -0.9993997  -0.9992519  -0.99859244 -0.9725504\n",
      "  -0.9833791  -0.98043716 -0.99029535 -0.9982683 ]\n",
      " [ 1.          0.99570477 -0.999215   -0.99864274 -0.9981416  -0.9605535\n",
      "  -0.9816618  -0.97378737 -0.9871076  -0.99844915]\n",
      " [ 1.          0.9944955  -0.9991005  -0.99840677 -0.99786824 -0.96339804\n",
      "  -0.9801988  -0.97578627 -0.9865871  -0.99850726]\n",
      " [ 1.          0.9955718  -0.99918526 -0.99857557 -0.9980171  -0.96284944\n",
      "  -0.9816916  -0.9751993  -0.9867965  -0.9985051 ]\n",
      " [ 1.          0.9955374  -0.9991214  -0.9985262  -0.99802285 -0.96360576\n",
      "  -0.9807857  -0.97535807 -0.9883959  -0.998553  ]\n",
      " [ 1.          0.99531275 -0.9991299  -0.99858344 -0.9979633  -0.9634387\n",
      "  -0.98147225 -0.97554326 -0.98811054 -0.9985458 ]\n",
      " [ 1.          0.9955394  -0.9991902  -0.9986179  -0.9981122  -0.9624204\n",
      "  -0.9813739  -0.97443956 -0.9875413  -0.9985045 ]\n",
      " [ 1.          0.99557155 -0.9991839  -0.998508   -0.9981369  -0.9624644\n",
      "  -0.9807003  -0.97453356 -0.98712724 -0.9985162 ]\n",
      " [ 1.          0.99499977 -0.99913186 -0.99850523 -0.99793047 -0.9618197\n",
      "  -0.98192644 -0.9750499  -0.98775655 -0.9984519 ]\n",
      " [ 1.          0.9944057  -0.99913085 -0.9983971  -0.9978661  -0.9652989\n",
      "  -0.98019123 -0.9762172  -0.98767287 -0.99863625]\n",
      " [ 1.          0.9952368  -0.9991649  -0.9985509  -0.99807596 -0.9636448\n",
      "  -0.98013157 -0.9744494  -0.9882005  -0.9986388 ]\n",
      " [ 1.          0.995092   -0.9992361  -0.99858034 -0.9981616  -0.9631886\n",
      "  -0.9808565  -0.974908   -0.9873922  -0.99862224]\n",
      " [ 1.          0.9944064  -0.99915814 -0.99853796 -0.9979785  -0.966155\n",
      "  -0.9793697  -0.9754869  -0.9875301  -0.99865377]\n",
      " [ 1.          0.9989311  -0.99942213 -0.99930704 -0.99862725 -0.97269523\n",
      "  -0.982899   -0.98073167 -0.99067116 -0.9984481 ]\n",
      " [ 1.          0.9961764  -0.99918056 -0.9986731  -0.9979589  -0.9620114\n",
      "  -0.9826945  -0.9763562  -0.9877077  -0.99852914]\n",
      " [ 1.          0.99469835 -0.99923635 -0.9985838  -0.99798    -0.9641705\n",
      "  -0.98071957 -0.9754743  -0.98769474 -0.99868184]\n",
      " [ 1.          0.9950287  -0.99913615 -0.9985175  -0.99785507 -0.9628544\n",
      "  -0.98128027 -0.97671837 -0.9873054  -0.99857765]\n",
      " [ 1.          0.9941977  -0.99911374 -0.99847585 -0.99787    -0.96403825\n",
      "  -0.9798294  -0.97614706 -0.987316   -0.9986311 ]\n",
      " [ 1.          0.9960107  -0.9992529  -0.9987364  -0.99831164 -0.96398574\n",
      "  -0.9808405  -0.97399104 -0.9883329  -0.998584  ]\n",
      " [ 1.          0.9956866  -0.9991444  -0.9985545  -0.99801654 -0.9616996\n",
      "  -0.9811671  -0.9748374  -0.98753047 -0.99843454]\n",
      " [ 1.          0.99894136 -0.99944776 -0.99927694 -0.9986813  -0.9739679\n",
      "  -0.98195136 -0.981943   -0.9911237  -0.9983652 ]\n",
      " [ 1.          0.9987804  -0.9993997  -0.9992519  -0.99859244 -0.9725504\n",
      "  -0.9833791  -0.98043716 -0.99029535 -0.9982683 ]\n",
      " [ 1.          0.99570477 -0.999215   -0.99864274 -0.9981416  -0.9605535\n",
      "  -0.9816618  -0.97378737 -0.9871076  -0.99844915]\n",
      " [ 1.          0.9944955  -0.9991005  -0.99840677 -0.99786824 -0.96339804\n",
      "  -0.9801988  -0.97578627 -0.9865871  -0.99850726]\n",
      " [ 1.          0.9955718  -0.99918526 -0.99857557 -0.9980171  -0.96284944\n",
      "  -0.9816916  -0.9751993  -0.9867965  -0.9985051 ]\n",
      " [ 1.          0.9955374  -0.9991214  -0.9985262  -0.99802285 -0.96360576\n",
      "  -0.9807857  -0.97535807 -0.9883959  -0.998553  ]]\n",
      "<NDArray 30x10 @cpu(0)>]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training acc at epoch 5: accuracy=0.833333\n",
      "[\n",
      "[[ 1.          0.99317515 -0.9991286  -0.99846625 -0.99784625 -0.97044706\n",
      "  -0.9795389  -0.9781106  -0.9880768  -0.99875593]\n",
      " [ 1.          0.9947343  -0.9991909  -0.9985592  -0.9979984  -0.96582127\n",
      "  -0.9817671  -0.9767409  -0.9876011  -0.998574  ]\n",
      " [ 1.          0.99883795 -0.9994588  -0.9992672  -0.9986752  -0.9766773\n",
      "  -0.9824077  -0.9832479  -0.9914651  -0.99841714]\n",
      " [ 1.          0.9941195  -0.9991355  -0.99846935 -0.9979318  -0.96857715\n",
      "  -0.98015445 -0.97730696 -0.98865914 -0.998758  ]\n",
      " [ 1.          0.993283   -0.9991105  -0.99833274 -0.99774355 -0.96961194\n",
      "  -0.98042166 -0.97862417 -0.9882331  -0.9987371 ]\n",
      " [ 1.          0.99331844 -0.9990799  -0.99833965 -0.99775726 -0.9680122\n",
      "  -0.9802989  -0.97811973 -0.98722696 -0.99861944]\n",
      " [ 1.          0.99285173 -0.99908143 -0.9983997  -0.99773735 -0.9688597\n",
      "  -0.97982943 -0.9787276  -0.98783356 -0.9987479 ]\n",
      " [ 1.          0.994534   -0.9991623  -0.9985329  -0.9979677  -0.9674815\n",
      "  -0.98142564 -0.9772523  -0.9880699  -0.9986289 ]\n",
      " [ 1.          0.9935996  -0.99920386 -0.9984982  -0.99781245 -0.9686781\n",
      "  -0.98103994 -0.9783148  -0.9882276  -0.99877673]\n",
      " [ 1.          0.9939765  -0.9992061  -0.99849117 -0.99801147 -0.9680746\n",
      "  -0.98105294 -0.97792476 -0.9879159  -0.99873006]\n",
      " [ 1.          0.99868447 -0.99941456 -0.99925596 -0.9986007  -0.9752784\n",
      "  -0.9838173  -0.98182034 -0.9905323  -0.99832165]\n",
      " [ 1.          0.995329   -0.9991609  -0.9985996  -0.99780226 -0.96698636\n",
      "  -0.98289335 -0.9790584  -0.98818797 -0.9986464 ]\n",
      " [ 1.          0.9946581  -0.9991163  -0.99846286 -0.9978665  -0.9670204\n",
      "  -0.98114514 -0.97765386 -0.9880569  -0.99856985]\n",
      " [ 1.          0.9988518  -0.9994304  -0.9993048  -0.9986337  -0.9752188\n",
      "  -0.98342806 -0.9819983  -0.99095637 -0.99847865]\n",
      " [ 1.          0.994493   -0.99908984 -0.9984412  -0.9978742  -0.968618\n",
      "  -0.9808206  -0.9781846  -0.9888905  -0.9986795 ]\n",
      " [ 1.          0.99463695 -0.99916387 -0.9984931  -0.9978637  -0.9676173\n",
      "  -0.98187566 -0.97790784 -0.98736143 -0.9986214 ]\n",
      " [ 1.          0.994247   -0.99910116 -0.99850833 -0.9978208  -0.96830064\n",
      "  -0.9815181  -0.97823286 -0.9885481  -0.99867105]\n",
      " [ 1.          0.99454165 -0.99916136 -0.99841684 -0.9979972  -0.9675886\n",
      "  -0.98072094 -0.97740394 -0.98764545 -0.99864113]\n",
      " [ 1.          0.9938929  -0.99910146 -0.99841774 -0.99777615 -0.9668126\n",
      "  -0.9820705  -0.9778064  -0.9882683  -0.99857366]\n",
      " [ 1.          0.99510175 -0.99923223 -0.9986702  -0.998186   -0.96876484\n",
      "  -0.9810115  -0.97694075 -0.98885185 -0.9987005 ]\n",
      " [ 1.          0.99391913 -0.99911153 -0.99844193 -0.99771225 -0.967842\n",
      "  -0.9813678  -0.97929966 -0.98785186 -0.9986971 ]\n",
      " [ 1.          0.99317515 -0.9991286  -0.99846625 -0.99784625 -0.97044706\n",
      "  -0.9795389  -0.9781106  -0.9880768  -0.99875593]\n",
      " [ 1.          0.9947343  -0.9991909  -0.9985592  -0.9979984  -0.96582127\n",
      "  -0.9817671  -0.9767409  -0.9876011  -0.998574  ]\n",
      " [ 1.          0.99883795 -0.9994588  -0.9992672  -0.9986752  -0.9766773\n",
      "  -0.9824077  -0.9832479  -0.9914651  -0.99841714]\n",
      " [ 1.          0.9941195  -0.9991355  -0.99846935 -0.9979318  -0.96857715\n",
      "  -0.98015445 -0.97730696 -0.98865914 -0.998758  ]\n",
      " [ 1.          0.993283   -0.9991105  -0.99833274 -0.99774355 -0.96961194\n",
      "  -0.98042166 -0.97862417 -0.9882331  -0.9987371 ]\n",
      " [ 1.          0.99331844 -0.9990799  -0.99833965 -0.99775726 -0.9680122\n",
      "  -0.9802989  -0.97811973 -0.98722696 -0.99861944]\n",
      " [ 1.          0.99285173 -0.99908143 -0.9983997  -0.99773735 -0.9688597\n",
      "  -0.97982943 -0.9787276  -0.98783356 -0.9987479 ]\n",
      " [ 1.          0.994534   -0.9991623  -0.9985329  -0.9979677  -0.9674815\n",
      "  -0.98142564 -0.9772523  -0.9880699  -0.9986289 ]\n",
      " [ 1.          0.9935996  -0.99920386 -0.9984982  -0.99781245 -0.9686781\n",
      "  -0.98103994 -0.9783148  -0.9882276  -0.99877673]]\n",
      "<NDArray 30x10 @cpu(0)>]\n",
      "training acc at epoch 6: accuracy=0.866667\n",
      "[\n",
      "[[ 1.          0.9916664  -0.9990591  -0.9982899  -0.9976721  -0.97146916\n",
      "  -0.9804337  -0.98003405 -0.9878024  -0.99872386]\n",
      " [ 1.          0.994038   -0.99914646 -0.99852574 -0.99765486 -0.9708055\n",
      "  -0.9830728  -0.9812616  -0.9886192  -0.99875706]\n",
      " [ 1.          0.99305004 -0.9991465  -0.99834    -0.9978849  -0.9714768\n",
      "  -0.980683   -0.9796328  -0.9880809  -0.9987614 ]\n",
      " [ 1.          0.9929893  -0.99906677 -0.99837583 -0.9977681  -0.9723934\n",
      "  -0.9807661  -0.98033595 -0.98925555 -0.9987989 ]\n",
      " [ 1.          0.991761   -0.9990937  -0.9982913  -0.9976617  -0.97274584\n",
      "  -0.9806671  -0.98049796 -0.9886756  -0.9988275 ]\n",
      " [ 1.          0.99249595 -0.9991112  -0.99840355 -0.9978226  -0.9722947\n",
      "  -0.9800827  -0.9795489  -0.98897094 -0.9988713 ]\n",
      " [ 1.          0.9984965  -0.9994287  -0.9992502  -0.99859875 -0.9776079\n",
      "  -0.98411345 -0.9830177  -0.9907085  -0.9983971 ]\n",
      " [ 1.          0.99316335 -0.9990941  -0.9983847  -0.99774355 -0.9710589\n",
      "  -0.9810798  -0.9798653  -0.9884893  -0.9986985 ]\n",
      " [ 1.          0.99308854 -0.9991329  -0.9984496  -0.9978327  -0.9713195\n",
      "  -0.9814286  -0.97954863 -0.9884864  -0.99874526]\n",
      " [ 1.          0.9914694  -0.9990995  -0.9984152  -0.9977483  -0.97352064\n",
      "  -0.9797795  -0.98022354 -0.98850954 -0.99884707]\n",
      " [ 1.          0.99236256 -0.99917454 -0.9984057  -0.9978736  -0.9717382\n",
      "  -0.9812476  -0.9803913  -0.98836297 -0.99882835]\n",
      " [ 1.          0.9923629  -0.9990907  -0.99838465 -0.99761105 -0.97158456\n",
      "  -0.9814349  -0.981321   -0.9883056  -0.99880505]\n",
      " [ 1.          0.991017   -0.99905014 -0.9983504  -0.99765223 -0.9723707\n",
      "  -0.9798616  -0.9807631  -0.98822737 -0.9988504 ]\n",
      " [ 1.          0.9924037  -0.99907386 -0.99834746 -0.9976514  -0.9704766\n",
      "  -0.9822582  -0.98000556 -0.98866713 -0.9986796 ]\n",
      " [ 1.          0.9933573  -0.9991471  -0.9984172  -0.99772525 -0.97108614\n",
      "  -0.9821029  -0.98002243 -0.9878859  -0.99872285]\n",
      " [ 1.          0.99864835 -0.9994709  -0.9992473  -0.9986544  -0.9790584\n",
      "  -0.9826961  -0.9843817  -0.9918257  -0.99849606]\n",
      " [ 1.          0.99327403 -0.9991646  -0.9984675  -0.99785006 -0.96994245\n",
      "  -0.9818553  -0.97925454 -0.988081   -0.99869376]\n",
      " [ 1.          0.99369246 -0.9992061  -0.99859196 -0.99805564 -0.9724654\n",
      "  -0.9810739  -0.97947    -0.9892064  -0.99881285]\n",
      " [ 1.          0.99272144 -0.9990733  -0.9984449  -0.99770534 -0.97194487\n",
      "  -0.98151296 -0.9803958  -0.9888315  -0.998786  ]\n",
      " [ 1.          0.9987013  -0.99943984 -0.9992945  -0.9986287  -0.97742337\n",
      "  -0.98381376 -0.98311615 -0.9912235  -0.9985332 ]\n",
      " [ 1.          0.99212116 -0.9991736  -0.99842715 -0.99767506 -0.9718792\n",
      "  -0.98141545 -0.9805575  -0.9886316  -0.99885654]\n",
      " [ 1.          0.9916664  -0.9990591  -0.9982899  -0.9976721  -0.97146916\n",
      "  -0.9804337  -0.98003405 -0.9878024  -0.99872386]\n",
      " [ 1.          0.994038   -0.99914646 -0.99852574 -0.99765486 -0.9708055\n",
      "  -0.9830728  -0.9812616  -0.9886192  -0.99875706]\n",
      " [ 1.          0.99305004 -0.9991465  -0.99834    -0.9978849  -0.9714768\n",
      "  -0.980683   -0.9796328  -0.9880809  -0.9987614 ]\n",
      " [ 1.          0.9929893  -0.99906677 -0.99837583 -0.9977681  -0.9723934\n",
      "  -0.9807661  -0.98033595 -0.98925555 -0.9987989 ]\n",
      " [ 1.          0.991761   -0.9990937  -0.9982913  -0.9976617  -0.97274584\n",
      "  -0.9806671  -0.98049796 -0.9886756  -0.9988275 ]\n",
      " [ 1.          0.99249595 -0.9991112  -0.99840355 -0.9978226  -0.9722947\n",
      "  -0.9800827  -0.9795489  -0.98897094 -0.9988713 ]\n",
      " [ 1.          0.9984965  -0.9994287  -0.9992502  -0.99859875 -0.9776079\n",
      "  -0.98411345 -0.9830177  -0.9907085  -0.9983971 ]\n",
      " [ 1.          0.99316335 -0.9990941  -0.9983847  -0.99774355 -0.9710589\n",
      "  -0.9810798  -0.9798653  -0.9884893  -0.9986985 ]\n",
      " [ 1.          0.99308854 -0.9991329  -0.9984496  -0.9978327  -0.9713195\n",
      "  -0.9814286  -0.97954863 -0.9884864  -0.99874526]]\n",
      "<NDArray 30x10 @cpu(0)>]\n",
      "training acc at epoch 7: accuracy=0.866667\n",
      "[\n",
      "[[ 1.          0.9911784  -0.9991017  -0.9984009  -0.99775463 -0.9740168\n",
      "  -0.98147935 -0.981339   -0.98875594 -0.9988397 ]\n",
      " [ 1.          0.99048394 -0.9990447  -0.998317   -0.99759054 -0.973017\n",
      "  -0.9825414  -0.98177487 -0.98890305 -0.998761  ]\n",
      " [ 1.          0.9906381  -0.99904174 -0.998415   -0.99764943 -0.9745459\n",
      "  -0.98155683 -0.98213756 -0.988993   -0.9988805 ]\n",
      " [ 1.          0.9902053  -0.99914175 -0.99835813 -0.9977959  -0.9742841\n",
      "  -0.98151565 -0.9823502  -0.9886462  -0.9989063 ]\n",
      " [ 1.          0.98943216 -0.9990293  -0.9982737  -0.997639   -0.9739532\n",
      "  -0.98062456 -0.98167425 -0.9881758  -0.9988104 ]\n",
      " [ 1.          0.9984626  -0.9994523  -0.99927974 -0.99861825 -0.9794157\n",
      "  -0.98407    -0.98413604 -0.9914599  -0.9986089 ]\n",
      " [ 1.          0.9911136  -0.99907213 -0.9983465  -0.99768573 -0.9739637\n",
      "  -0.9810533  -0.98160547 -0.9887622  -0.9988067 ]\n",
      " [ 1.          0.9897197  -0.9990708  -0.99828166 -0.997637   -0.9749767\n",
      "  -0.9809412  -0.98204625 -0.98894984 -0.9989018 ]\n",
      " [ 1.          0.990292   -0.9990654  -0.99836415 -0.99758065 -0.97425306\n",
      "  -0.9815409  -0.98295486 -0.9885722  -0.99889153]\n",
      " [ 1.          0.9902078  -0.999144   -0.9983937  -0.9976047  -0.9740304\n",
      "  -0.9818756  -0.98233014 -0.9888659  -0.99891645]\n",
      " [ 1.          0.9908998  -0.9990443  -0.99835026 -0.9977334  -0.9751426\n",
      "  -0.9807013  -0.9820245  -0.98946375 -0.9989015 ]\n",
      " [ 1.          0.99173635 -0.99913394 -0.9983727  -0.9976387  -0.97341627\n",
      "  -0.9824339  -0.9816644  -0.9882409  -0.99879926]\n",
      " [ 1.          0.98917586 -0.9990644  -0.99839836 -0.99770933 -0.97565496\n",
      "  -0.9800934  -0.98197144 -0.9887694  -0.9989208 ]\n",
      " [ 1.          0.9910291  -0.9991341  -0.99830407 -0.99783623 -0.9742522\n",
      "  -0.9806723  -0.9813627  -0.9883559  -0.99886274]\n",
      " [ 1.          0.9983653  -0.9994872  -0.99922526 -0.9986326  -0.98110044\n",
      "  -0.9828466  -0.9853317  -0.99213296 -0.9985904 ]\n",
      " [ 1.          0.9885718  -0.99901223 -0.9983379  -0.9976309  -0.9748498\n",
      "  -0.9799825  -0.982448   -0.9884595  -0.9989315 ]\n",
      " [ 1.          0.9902657  -0.9990854  -0.99837583 -0.99778056 -0.97493535\n",
      "  -0.9800345  -0.9813109  -0.98914623 -0.99896586]\n",
      " [ 1.          0.99169236 -0.99917567 -0.99853426 -0.99796325 -0.9751062\n",
      "  -0.98116404 -0.98154575 -0.9893948  -0.9989071 ]\n",
      " [ 1.          0.99134696 -0.999138   -0.99840856 -0.99775475 -0.97280574\n",
      "  -0.9820585  -0.9812535  -0.9884123  -0.99878675]\n",
      " [ 1.          0.9981922  -0.9994433  -0.9992391  -0.998591   -0.97971076\n",
      "  -0.98431855 -0.9841736  -0.99084777 -0.99848884]\n",
      " [ 1.          0.99226487 -0.99913603 -0.99848187 -0.99756056 -0.9734558\n",
      "  -0.98337156 -0.98304397 -0.98889536 -0.99884474]\n",
      " [ 1.          0.9911784  -0.9991017  -0.9984009  -0.99775463 -0.9740168\n",
      "  -0.98147935 -0.981339   -0.98875594 -0.9988397 ]\n",
      " [ 1.          0.99048394 -0.9990447  -0.998317   -0.99759054 -0.973017\n",
      "  -0.9825414  -0.98177487 -0.98890305 -0.998761  ]\n",
      " [ 1.          0.9906381  -0.99904174 -0.998415   -0.99764943 -0.9745459\n",
      "  -0.98155683 -0.98213756 -0.988993   -0.9988805 ]\n",
      " [ 1.          0.9902053  -0.99914175 -0.99835813 -0.9977959  -0.9742841\n",
      "  -0.98151565 -0.9823502  -0.9886462  -0.9989063 ]\n",
      " [ 1.          0.98943216 -0.9990293  -0.9982737  -0.997639   -0.9739532\n",
      "  -0.98062456 -0.98167425 -0.9881758  -0.9988104 ]\n",
      " [ 1.          0.9984626  -0.9994523  -0.99927974 -0.99861825 -0.9794157\n",
      "  -0.98407    -0.98413604 -0.9914599  -0.9986089 ]\n",
      " [ 1.          0.9911136  -0.99907213 -0.9983465  -0.99768573 -0.9739637\n",
      "  -0.9810533  -0.98160547 -0.9887622  -0.9988067 ]\n",
      " [ 1.          0.9897197  -0.9990708  -0.99828166 -0.997637   -0.9749767\n",
      "  -0.9809412  -0.98204625 -0.98894984 -0.9989018 ]\n",
      " [ 1.          0.990292   -0.9990654  -0.99836415 -0.99758065 -0.97425306\n",
      "  -0.9815409  -0.98295486 -0.9885722  -0.99889153]]\n",
      "<NDArray 30x10 @cpu(0)>]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training acc at epoch 8: accuracy=0.866667\n",
      "[\n",
      "[[ 1.          0.9872096  -0.99898654 -0.998319   -0.9975932  -0.9750198\n",
      "  -0.98277897 -0.9835686  -0.98897624 -0.9988359 ]\n",
      " [ 1.          0.9876999  -0.99902135 -0.99834085 -0.9976903  -0.97617155\n",
      "  -0.9810323  -0.9833106  -0.9888822  -0.99890083]\n",
      " [ 1.          0.9856103  -0.9989652  -0.9982856  -0.9976595  -0.9759495\n",
      "  -0.9807581  -0.9834216  -0.98834354 -0.9988916 ]\n",
      " [ 1.          0.9844694  -0.9989448  -0.9983494  -0.9976643  -0.97678417\n",
      "  -0.9801085  -0.9841886  -0.988521   -0.99900204]\n",
      " [ 1.          0.9869285  -0.9990927  -0.99838877 -0.9976021  -0.97574514\n",
      "  -0.9822243  -0.9840457  -0.98894644 -0.99897546]\n",
      " [ 1.          0.98526007 -0.99899983 -0.9984037  -0.99772984 -0.9773901\n",
      "  -0.98027027 -0.9837161  -0.9888641  -0.9989929 ]\n",
      " [ 1.          0.98943293 -0.9991067  -0.9984667  -0.99752903 -0.9753351\n",
      "  -0.98373586 -0.98472667 -0.9889912  -0.99891585]\n",
      " [ 1.          0.98617697 -0.9990178  -0.9982938  -0.99766594 -0.9767969\n",
      "  -0.98110205 -0.98364264 -0.9890739  -0.998974  ]\n",
      " [ 1.          0.98817784 -0.99908924 -0.9983854  -0.9977258  -0.9749391\n",
      "  -0.98227805 -0.9831684  -0.9885536  -0.9988664 ]\n",
      " [ 1.          0.98741263 -0.99899364 -0.9983534  -0.9977607  -0.97723854\n",
      "  -0.98062474 -0.98369443 -0.9895239  -0.9989908 ]\n",
      " [ 1.          0.9979495  -0.99950475 -0.99920386 -0.9986151  -0.9827268\n",
      "  -0.98295283 -0.9861166  -0.99235225 -0.9986883 ]\n",
      " [ 1.          0.9865098  -0.99903184 -0.9983758  -0.9977994  -0.9769591\n",
      "  -0.9799716  -0.9830691  -0.9891951  -0.9990485 ]\n",
      " [ 1.          0.99766314 -0.9994493  -0.999224   -0.99857223 -0.98142105\n",
      "  -0.98460025 -0.9854153  -0.9909304  -0.9985844 ]\n",
      " [ 1.          0.99808025 -0.99946487 -0.99926287 -0.9986056  -0.98111415\n",
      "  -0.9842828  -0.98511827 -0.9916306  -0.99869764]\n",
      " [ 1.          0.98658234 -0.9990858  -0.9983445  -0.99778885 -0.9763038\n",
      "  -0.98163974 -0.98415554 -0.98877007 -0.9989821 ]\n",
      " [ 1.          0.9883597  -0.9991229  -0.99850124 -0.9979267  -0.97711915\n",
      "  -0.9811695  -0.98341775 -0.9894641  -0.9989936 ]\n",
      " [ 1.          0.98911256 -0.9991043  -0.9983573  -0.9976085  -0.9750696\n",
      "  -0.98282385 -0.9832888  -0.9883877  -0.9988606 ]\n",
      " [ 1.          0.9866952  -0.99900556 -0.9983728  -0.9976177  -0.97638077\n",
      "  -0.98157233 -0.9846678  -0.9886409  -0.99897134]\n",
      " [ 1.          0.987063   -0.99897957 -0.99841195 -0.99765265 -0.97658956\n",
      "  -0.981572   -0.98389006 -0.9890354  -0.998966  ]\n",
      " [ 1.          0.98766303 -0.9990952  -0.9983015  -0.9978501  -0.9763689\n",
      "  -0.98064125 -0.98307216 -0.98847294 -0.99895173]\n",
      " [ 1.          0.9879837  -0.9990453  -0.99838483 -0.9977386  -0.9760928\n",
      "  -0.9815006  -0.9830629  -0.9888894  -0.99892443]\n",
      " [ 1.          0.9872096  -0.99898654 -0.998319   -0.9975932  -0.9750198\n",
      "  -0.98277897 -0.9835686  -0.98897624 -0.9988359 ]\n",
      " [ 1.          0.9876999  -0.99902135 -0.99834085 -0.9976903  -0.97617155\n",
      "  -0.9810323  -0.9833106  -0.9888822  -0.99890083]\n",
      " [ 1.          0.9856103  -0.9989652  -0.9982856  -0.9976595  -0.9759495\n",
      "  -0.9807581  -0.9834216  -0.98834354 -0.9988916 ]\n",
      " [ 1.          0.9844694  -0.9989448  -0.9983494  -0.9976643  -0.97678417\n",
      "  -0.9801085  -0.9841886  -0.988521   -0.99900204]\n",
      " [ 1.          0.9869285  -0.9990927  -0.99838877 -0.9976021  -0.97574514\n",
      "  -0.9822243  -0.9840457  -0.98894644 -0.99897546]\n",
      " [ 1.          0.98526007 -0.99899983 -0.9984037  -0.99772984 -0.9773901\n",
      "  -0.98027027 -0.9837161  -0.9888641  -0.9989929 ]\n",
      " [ 1.          0.98943293 -0.9991067  -0.9984667  -0.99752903 -0.9753351\n",
      "  -0.98373586 -0.98472667 -0.9889912  -0.99891585]\n",
      " [ 1.          0.98617697 -0.9990178  -0.9982938  -0.99766594 -0.9767969\n",
      "  -0.98110205 -0.98364264 -0.9890739  -0.998974  ]\n",
      " [ 1.          0.98817784 -0.99908924 -0.9983854  -0.9977258  -0.9749391\n",
      "  -0.98227805 -0.9831684  -0.9885536  -0.9988664 ]]\n",
      "<NDArray 30x10 @cpu(0)>]\n",
      "training acc at epoch 9: accuracy=0.900000\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "# lr_lst = [0.001, 0.005, 0.01, 0.05, 0.1]\n",
    "# low learning rate, high momentum\n",
    "lr_lst = [0.02]\n",
    "\n",
    "train_acc_over_hyperparam_tensor = []\n",
    "# val_acc_over_hyperparam_tensor = []\n",
    "\n",
    "for lr_val in lr_lst:\n",
    "    # set learning rate\n",
    "    trainer.set_learning_rate(lr_val)\n",
    "    \n",
    "    # store results\n",
    "    train_acc_lst = np.zeros(epochs)\n",
    "#     val_acc_lst = np.zeros(epochs)\n",
    "\n",
    "    for i in range(epochs):\n",
    "        # Reset the train data iterator.\n",
    "        train_data.reset()\n",
    "        # Loop over the train data iterator.\n",
    "        for batch in train_data:\n",
    "            # Splits train data into multiple slices along batch_axis\n",
    "            # and copy each slice into a context.\n",
    "            data = gluon.utils.split_and_load(batch.data[0], ctx_list=ctx, batch_axis=0)\n",
    "            # Splits train labels into multiple slices along batch_axis\n",
    "            # and copy each slice into a context.\n",
    "            label = gluon.utils.split_and_load(batch.label[0], ctx_list=ctx, batch_axis=0)\n",
    "            outputs = []\n",
    "            # Inside training scope\n",
    "            with ag.record():\n",
    "                for x, y in zip(data, label):\n",
    "                    z = net(x)\n",
    "                    # Computes softmax cross entropy loss.\n",
    "                    loss = softmax_cross_entropy_loss(z, y)\n",
    "                    # Backpropogate the error for one iteration.\n",
    "                    loss.backward()\n",
    "                    outputs.append(z)\n",
    "\n",
    "            print(outputs)\n",
    "            # Updates internal evaluation\n",
    "            metric.update(label, outputs)\n",
    "            # Make one step of parameter update. Trainer needs to know the\n",
    "            # batch size of data to normalize the gradient by 1/batch_size.\n",
    "            trainer.step(batch.data[0].shape[0])\n",
    "\n",
    "        # Gets the training evaluation result.\n",
    "        name, train_acc = metric.get()\n",
    "        train_acc_lst[i] = train_acc\n",
    "\n",
    "    #     # Gets the validation evaluation result.\n",
    "    #     name, val_acc = test(net,val_data,ctx)\n",
    "    #     val_acc_lst[i] = val_acc\n",
    "\n",
    "        # Reset evaluation result to initial state.\n",
    "        metric.reset()\n",
    "        print('training acc at epoch %d: %s=%f'%(i, name, train_acc))\n",
    "    \n",
    "    train_acc_over_hyperparam_tensor.append(train_acc_lst)\n",
    "#     val_acc_over_hyperparam_tensor.append(val_acc_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0,epochs,1),train_acc_over_hyperparam_tensor[0],'r')\n",
    "plt.ylabel('Training Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.title('CNN Classify Fluo Polarization')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# plt.figure()\n",
    "# plt.plot(np.arange(0,epochs,1),val_acc_lst,'r')\n",
    "# plt.ylabel('Validation Accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.title('CNN Classify Fluo Polarization')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
